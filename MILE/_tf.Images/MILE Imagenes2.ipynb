{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MILE.Imagenes2","version":"0.3.2","provenance":[],"collapsed_sections":["rsPvpfSzr8Jc","VbGjQ33fJeXj"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"metadata":{"id":"C7WTKdnOCTBr","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","import pathlib\n","import random\n","import tensorflow as tf\n","import tensorflow_hub as tfhub\n","#tf.enable_eager_execution()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pJjqwNTU9igJ","colab_type":"code","colab":{}},"cell_type":"code","source":["#Usados\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","train_steps = 400\n","train_batch_size = 5\n","eval_batch = 5\n","BATCH_SIZE = 5\n","\n","#No usados\n","#eval_delay_secs = 10\n","#throttle_secs = 300\n","#steps_per_epoch = 3\n","#summary_steps = 100\n","#log_step = 10\n","#epochs= 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Xndr4SoKCoKg","colab_type":"code","colab":{}},"cell_type":"code","source":["#tf.logging.info('TF Version {}'.format(tf.__version__))\n","#tf.logging.info('GPU Available {}'.format(tf.test.is_gpu_available()))\n","#if 'TF_CONFIG' in os.environ:\n","#    tf.logging.info('TF_CONFIG: {}'.format(os.environ[\"TF_CONFIG\"]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OfMTFRQebwpW","colab_type":"text"},"cell_type":"markdown","source":["**Rutas"]},{"metadata":{"id":"cTvGHTsPbrhc","colab_type":"code","colab":{}},"cell_type":"code","source":["# Modelo general\n","path_model = '/content/model/'\n","os.makedirs(os.path.join(path_model), exist_ok=True)\n","\n","# Modelo entrenado\n","path_trained = os.path.join(path_model, 'trained')\n","\n","# Modelo importado\n","TFHUB_CACHE_DIR = os.path.join(path_model, 'TFHub')\n","os.environ['TFHUB_CACHE_DIR'] = TFHUB_CACHE_DIR\n","\n","# Data importada\n","path_data = os.path.join(path_model, 'dogscats')\n","url_data = 'http://files.fast.ai/data/dogscats.zip'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rsPvpfSzr8Jc","colab_type":"text"},"cell_type":"markdown","source":["# Modelo importado\n","**Importacion**"]},{"metadata":{"id":"JQ6RhpC7Gstu","colab_type":"code","cellView":"code","colab":{}},"cell_type":"code","source":["classifier_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2\" #@param {type:\"string\"}\n","tfh_module = tfhub.Module(classifier_url)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eGIOpZtKb84r","colab_type":"text"},"cell_type":"markdown","source":["**Variables derivadas**"]},{"metadata":{"id":"tP5Oje0_cB1r","colab_type":"code","colab":{}},"cell_type":"code","source":["IMAGE_SIZE = tfhub.get_expected_image_size(tfh_module)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bUGN4GRzQUWL","colab_type":"text"},"cell_type":"markdown","source":["import shutil\n","shutil.rmtree('/content/model/trained', ignore_errors=False, onerror=None)"]},{"metadata":{"id":"XQuX7HjGsE0A","colab_type":"text"},"cell_type":"markdown","source":["# Datos\n"]},{"metadata":{"id":"__uDH3mWgzqe","colab_type":"text"},"cell_type":"markdown","source":["## Adquisicion"]},{"metadata":{"id":"Ts23GW9aC5U6","colab_type":"code","colab":{}},"cell_type":"code","source":["if not os.path.isdir(path_data):\n","  tf.keras.utils.get_file(fname = os.path.basename(url_data), origin = url_data, \n","                          cache_subdir=path_model, extract=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0-7uql7brwyV","colab_type":"text"},"cell_type":"markdown","source":["**Directorios de datos**"]},{"metadata":{"id":"jzq0-cW9seeY","colab_type":"code","colab":{}},"cell_type":"code","source":["train_path = os.path.join(path_data, 'train')\n","train_files = os.path.join(path_data, 'train', '**/*.jpg')\n","eval_path = os.path.join(path_data, 'valid')\n","eval_files = os.path.join(path_data, 'valid', '**/*.jpg')\n","pred_path = os.path.join(path_data, 'sample/train')\n","pred_files = os.path.join(path_data, 'sample/train','**/*.jpg')\n","pred_image = list(pathlib.Path(pred_path).glob('*/*'))\n","\n","data_root = pathlib.Path(train_path)\n","all_image_paths = list(data_root.glob('*/*'))\n","all_image_paths = [str(path) for path in all_image_paths]\n","random.shuffle(all_image_paths)\n","\n","label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n","label_to_index = dict((name, index) for index,name in enumerate(label_names))\n","all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n","                  for path in all_image_paths]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SAB72Jo4t61e","colab_type":"text"},"cell_type":"markdown","source":["---\n","For this output, you can connect additional layers according to the problem you want to solve. For example, if the problem is to classify images into 10 categories, you may want to continue fully connected-layer with 10 nodes, and apply the softmax function to have the probabilities.\n","\n","\n","logits = tf.layers.dense(inputs=outputs, units=10)\n","predictions = {\n","    \"classes\": tf.argmax(input=logits, axis=1),\n","    \"probabilities\": tf.nn.softmax(logits)\n","}\n","\n","---\n","train_input_fn = tf.data.Dataset.list_files(train_files)\n","\n","---\n","label = tf.string_split(source = [train_files], delimiter = '/').values[-2]\n","\n","---\n","from IPython.core.debugger import Tracer; Tracer()() \n","n, c, q"]},{"metadata":{"id":"Rf4wvxQnrtJF","colab_type":"text"},"cell_type":"markdown","source":["# Dataset"]},{"metadata":{"id":"0pehMuFNwI_m","colab_type":"code","colab":{}},"cell_type":"code","source":["def preprocess_image(image):\n","  image = tf.image.decode_jpeg(image, channels=3)\n","  image = tf.image.resize(image, [224, 224])\n","  image /= 255.0  # normalize to [0,1] range\n","  return image"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-ULil4K9wN-r","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_and_preprocess_image(path):\n","  image = tf.read_file(path)\n","  return preprocess_image(image)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-dKfYmmfBBQS","colab_type":"code","colab":{}},"cell_type":"code","source":["  paths_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n","  image_ds = paths_ds.map(load_and_preprocess_image)\n","  ds = image_ds.map(tf.serialize_tensor) \n","  tfrec = tf.data.experimental.TFRecordWriter('/content/model/images.tfrec')\n","  tfrec.write(ds)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BgIrBdPSKisJ","colab_type":"code","colab":{}},"cell_type":"code","source":["def read_dataset(filename, mode, batch_size):  \n","  \n","  #Toma la ruta de las imagenes, la decodifica, crea el tensor de atributos\n","  paths_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n","  image_ds = paths_ds.map(load_and_preprocess_image)\n","  \n","  ##\n","  #ds = image_ds.map(tf.serialize_tensor) \n","  #tfrec = tf.data.experimental.TFRecordWriter('/content/model/images.tfrec')\n","  #tfrec.write(ds)\n","  \n","  ds = tf.data.TFRecordDataset('/content/model/images.tfrec')\n","  def parse(x):\n","    result = tf.parse_tensor(x, out_type=tf.float32)\n","    result = tf.reshape(result, [224, 224, 3])\n","    return result\n","  ds = ds.map(parse, num_parallel_calls=AUTOTUNE)\n","  ##\n","  \n","  label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\n","  ds = tf.data.Dataset.zip((image_ds, label_ds))\n","  \n","  if mode == tf.estimator.ModeKeys.TRAIN:\n","    num_epochs = None #Loop indefinidamente\n","    ds = ds.shuffle(buffer_size = batch_size) # video 7:10 https://www.youtube.com/watch?v=uIcqeP7MFH0\n","    ds = ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=10*batch_size)) #10*batch_size -- image_count\n","  else:\n","    num_epochs = 1 #end-of-input after this\n","  \n","  ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE) # video 7:48\n","  return ds"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vBcgwKmDK1aC","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_input_fn():\n","    return read_dataset(\n","        filename = train_path, #args['train_data_paths']\n","        batch_size = train_batch_size, #args['train_batch_size']\n","        mode = tf.estimator.ModeKeys.TRAIN)\n","\n","def eval_input_fn():\n","  return read_dataset(\n","      filename = eval_path, #args['eval_data_paths']\n","      batch_size = eval_batch, \n","      mode = tf.estimator.ModeKeys.EVAL)\n","\n","def pred_input_fn():\n","  return read_dataset(\n","      filename = pred_path,\n","      batch_size = eval_batch, \n","      mode = tf.estimator.ModeKeys.PRED)\n","\n","def serving_input_fn():\n","  json_feature_placeholders = {\n","    'image' : tf.placeholder(tf.float32, [None]),}\n","  features = json_feature_placeholders\n","  return tf.estimator.export.ServingInputReceiver(features, json_feature_placeholders)\n","\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"VbGjQ33fJeXj","colab_type":"text"},"cell_type":"markdown","source":["# Modelo\n","**Configuracion del modelo importado**"]},{"metadata":{"id":"cOCKkRZx8pPr","colab_type":"code","colab":{}},"cell_type":"code","source":["def model_fn(features, labels, mode, params):\n","  #module = hub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_050_192/feature_vector/2\")\n","  #module = hub.Module(\"https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/1\")\n","  tfh_module=tfhub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2\")\n","  transformed_features = tfh_module(features)\n","  logits = tf.layers.dense(transformed_features, len(label_names))\n","  probabilities = tf.nn.softmax(logits)\n","  \n","  if (mode != tf.estimator.ModeKeys.PREDICT):\n","    one_hot_labels = tf.one_hot(labels, len(label_names))\n","    loss = tf.losses.softmax_cross_entropy(one_hot_labels, logits)\n","    optimizer = tf.train.AdamOptimizer() \n","    train_op = tf.contrib.training.create_train_op(loss, optimizer)\n","    accuracy = tf.metrics.accuracy(labels, tf.argmax(probabilities, axis=-1))\n","    metrics = {'acc':accuracy}\n","  else:\n","    # None of these can be computed in prediction mode because labels are not available\n","    loss = optimizer = train_op = metrics = None\n","  \n","  return tf.estimator.EstimatorSpec(\n","      mode=mode,\n","      loss=loss,\n","      train_op=train_op,\n","      # Nice: in estimator, you can return computed results that are not part of model training (here: class)\n","      predictions={'proba': probabilities, 'class': tf.argmax(probabilities, axis=-1)},\n","      eval_metric_ops=metrics\n","  )"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WPlZsHN78MEl","colab_type":"text"},"cell_type":"markdown","source":["# Entrenamiento"]},{"metadata":{"id":"wmkUyMDqJhHO","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_and_evaluate(): #args\n","  # Estimador del modelo a usar\n","  run_config = tf.estimator.RunConfig(\n","    model_dir = path_trained) #args['output_dir'],  Ouput directory for checkpoint\n","    #save_summary_steps = summary_steps, \n","    #save_checkpoints_steps = steps_per_epoch, #, save_checkpoints_step = 100\n","    #log_step_count_steps=log_step)\n","\n","  # Define los aspectos del modelo # ojo aqui esta el transfer learning\n","  model = tf.estimator.Estimator(\n","    model_fn = model_fn,\n","    config = run_config)\n","\n","  # Define los aspectos del entrenamiento y la entrada de datos\n","  train_spec = tf.estimator.TrainSpec(\n","    input_fn = train_input_fn, \n","    max_steps = train_steps) #args['train_steps']\n","\n","  # Define los aspectos del uso en produccion con ML Engine\n","  export_latest = tf.estimator.LatestExporter(\n","    'exporter', #folder to export\n","    serving_input_receiver_fn = serving_input_fn)\n","\n","  # Define los aspectos de la evaluacion, cada cuanto se graba para tensorboard y la entrada de datos\n","  eval_spec = tf.estimator.EvalSpec(\n","    input_fn = eval_input_fn)\n","    #steps = None,\n","    #start_delay_secs = eval_delay_secs, # args['eval_delay_secs'] start evaluating after N seconds\n","    #throttle_secs = throttle_secs) #, args['throttle_secs'] evaluate every N seconds\n","    #exporters = export_latest)\n","\n","  # Ejecuta el modelo\n","  out = tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n","  return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xo64AqHiBKOm","colab_type":"code","colab":{}},"cell_type":"code","source":["import shutil \n","shutil.rmtree('/content/model/trained', ignore_errors=False, onerror=None)\n","trained_model = train_and_evaluate()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YFF7-jqoiJk7","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}