{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MILE.Imagenes3","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"C7WTKdnOCTBr","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","import pathlib\n","import random\n","import tensorflow as tf\n","import tensorflow_hub as tfhub\n","#tf.enable_eager_execution()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pJjqwNTU9igJ","colab_type":"code","colab":{}},"cell_type":"code","source":["#Usados\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","train_steps = 2000\n","train_batch_size = 5\n","eval_batch = 5\n","BATCH_SIZE = 5\n","\n","#No usados\n","#eval_delay_secs = 10\n","#throttle_secs = 300\n","#steps_per_epoch = 3\n","#summary_steps = 100\n","#log_step = 10\n","#epochs= 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Xndr4SoKCoKg","colab_type":"code","outputId":"f5acbb21-cedd-4922-d77b-a56bb64ab7cd","executionInfo":{"status":"ok","timestamp":1556423678598,"user_tz":300,"elapsed":1795,"user":{"displayName":"Hernán Lopez Archila","photoUrl":"https://lh4.googleusercontent.com/-notp8jonoeY/AAAAAAAAAAI/AAAAAAAAfV4/x2JEFyvg6TM/s64/photo.jpg","userId":"11762393844550192215"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"cell_type":"code","source":["tf.logging.info('TF Version {}'.format(tf.__version__))\n","tf.logging.info('GPU Available {}'.format(tf.test.is_gpu_available()))\n","if 'TF_CONFIG' in os.environ:\n","    tf.logging.info('TF_CONFIG: {}'.format(os.environ[\"TF_CONFIG\"]))"],"execution_count":68,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:TF Version 1.13.1\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:38.434960 140433646442368 <ipython-input-68-33f139de6631>:1] TF Version 1.13.1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:GPU Available True\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:38.445271 140433646442368 <ipython-input-68-33f139de6631>:2] GPU Available True\n"],"name":"stderr"}]},{"metadata":{"id":"OfMTFRQebwpW","colab_type":"text"},"cell_type":"markdown","source":["**Rutas**"]},{"metadata":{"id":"cTvGHTsPbrhc","colab_type":"code","colab":{}},"cell_type":"code","source":["# Modelo general\n","path_model = '/content/model/'\n","os.makedirs(os.path.join(path_model), exist_ok=True)\n","\n","# Modelo entrenado\n","path_trained = os.path.join(path_model, 'trained')\n","\n","# Modelo importado\n","TFHUB_CACHE_DIR = os.path.join(path_model, 'TFHub')\n","os.environ['TFHUB_CACHE_DIR'] = TFHUB_CACHE_DIR\n","\n","# Data importada\n","path_data = os.path.join(path_model, 'dogscats')\n","url_data = 'http://files.fast.ai/data/dogscats.zip'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rsPvpfSzr8Jc","colab_type":"text"},"cell_type":"markdown","source":["# Modelo importado\n","**Importacion**"]},{"metadata":{"id":"JQ6RhpC7Gstu","colab_type":"code","cellView":"code","colab":{}},"cell_type":"code","source":["classifier_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2\" #@param {type:\"string\"}\n","tfh_module = tfhub.Module(classifier_url)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eGIOpZtKb84r","colab_type":"text"},"cell_type":"markdown","source":["**Variables derivadas**"]},{"metadata":{"id":"tP5Oje0_cB1r","colab_type":"code","colab":{}},"cell_type":"code","source":["IMAGE_SIZE = tfhub.get_expected_image_size(tfh_module)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bUGN4GRzQUWL","colab_type":"text"},"cell_type":"markdown","source":["import shutil\n","shutil.rmtree('/content/model/trained', ignore_errors=False, onerror=None)"]},{"metadata":{"id":"XQuX7HjGsE0A","colab_type":"text"},"cell_type":"markdown","source":["# Datos\n"]},{"metadata":{"id":"__uDH3mWgzqe","colab_type":"text"},"cell_type":"markdown","source":["## Adquisicion"]},{"metadata":{"id":"Ts23GW9aC5U6","colab_type":"code","colab":{}},"cell_type":"code","source":["if not os.path.isdir(path_data):\n","  tf.keras.utils.get_file(fname = os.path.basename(url_data), origin = url_data, \n","                          cache_subdir=path_model, extract=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0-7uql7brwyV","colab_type":"text"},"cell_type":"markdown","source":["**Directorios de datos**"]},{"metadata":{"id":"jzq0-cW9seeY","colab_type":"code","colab":{}},"cell_type":"code","source":["train_path = os.path.join(path_data, 'train')\n","eval_path = os.path.join(path_data, 'valid')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SAB72Jo4t61e","colab_type":"text"},"cell_type":"markdown","source":["---\n","For this output, you can connect additional layers according to the problem you want to solve. For example, if the problem is to classify images into 10 categories, you may want to continue fully connected-layer with 10 nodes, and apply the softmax function to have the probabilities.\n","\n","\n","logits = tf.layers.dense(inputs=outputs, units=10)\n","predictions = {\n","    \"classes\": tf.argmax(input=logits, axis=1),\n","    \"probabilities\": tf.nn.softmax(logits)\n","}\n","\n","---\n","train_input_fn = tf.data.Dataset.list_files(train_files)\n","\n","---\n","label = tf.string_split(source = [train_files], delimiter = '/').values[-2]\n","\n","---\n","from IPython.core.debugger import Tracer; Tracer()() \n","n, c, q"]},{"metadata":{"id":"Rf4wvxQnrtJF","colab_type":"text"},"cell_type":"markdown","source":["# Dataset"]},{"metadata":{"id":"0pehMuFNwI_m","colab_type":"code","colab":{}},"cell_type":"code","source":["def preprocess_image(image):\n","  image = tf.image.decode_jpeg(image, channels=3)\n","  image = tf.image.resize(image, [224, 224])\n","  image /= 255.0  # normalize to [0,1] range\n","  return image"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-ULil4K9wN-r","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_and_preprocess_image(path):\n","  image = tf.read_file(path)\n","  return preprocess_image(image)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BgIrBdPSKisJ","colab_type":"code","colab":{}},"cell_type":"code","source":["def read_dataset(filename, mode, batch_size, image, label):  \n","  \n","  #Toma la ruta de las imagenes, la decodifica, crea el tensor de atributos\n","  ds = tf.data.TFRecordDataset(filename)\n","  def parse(x):\n","    result = tf.parse_tensor(x, out_type=tf.float32)\n","    result = tf.reshape(result, [224, 224, 3])\n","    return result\n","  ds = ds.map(parse, num_parallel_calls=AUTOTUNE)\n","  \n","  ds = tf.data.Dataset.zip((image, label)) #<-------\n","  \n","  if mode == tf.estimator.ModeKeys.TRAIN:\n","    num_epochs = None #Loop indefinidamente\n","    ds = ds.shuffle(buffer_size = batch_size) # video 7:10 https://www.youtube.com/watch?v=uIcqeP7MFH0\n","    ds = ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=batch_size)) #10*batch_size -- image_count\n","  else:\n","    num_epochs = 1 #end-of-input after this\n","  \n","  ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE) # video 7:48\n","  return ds"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vBcgwKmDK1aC","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_input_fn():    \n","  data_root = pathlib.Path(train_path)#<------- filename\n","  all_image_paths = list(data_root.glob('*/*'))\n","  all_image_paths = [str(path) for path in all_image_paths]\n","  random.shuffle(all_image_paths)\n","\n","  if not os.path.isfile('/content/model/train.tfrec'):    #<------- tfr_file\n","    paths_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n","    image_ds = paths_ds.map(load_and_preprocess_image)\n","    ds = image_ds.map(tf.serialize_tensor) \n","    tfrec = tf.data.experimental.TFRecordWriter('/content/model/train.tfrec')#<------- tfr_file\n","    tfrec.write(ds)\n","\n","  label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n","  label_to_index = dict((name, index) for index,name in enumerate(label_names))\n","  all_image_labels = [label_to_index[pathlib.Path(path).parent.name]for path in all_image_paths]\n","  paths_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n","  image_ds = paths_ds.map(load_and_preprocess_image)\n","  label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\n","\n","  return read_dataset(filename = '/content/model/train.tfrec',#<-------\n","                      batch_size = train_batch_size, \n","                      mode = tf.estimator.ModeKeys.TRAIN,\n","                      image = image_ds,\n","                      label = label_ds)\n","\n","def eval_input_fn():\n","  data_root = pathlib.Path(eval_path)#<-------\n","  all_image_paths = list(data_root.glob('*/*'))\n","  all_image_paths = [str(path) for path in all_image_paths]\n","  random.shuffle(all_image_paths)\n","\n","  if not os.path.isfile('/content/model/eval.tfrec'):    #<-------\n","    paths_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n","    image_ds = paths_ds.map(load_and_preprocess_image)\n","    ds = image_ds.map(tf.serialize_tensor) \n","    tfrec = tf.data.experimental.TFRecordWriter('/content/model/eval.tfrec')#<-------\n","    tfrec.write(ds)\n","\n","  label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n","  label_to_index = dict((name, index) for index,name in enumerate(label_names))\n","  all_image_labels = [label_to_index[pathlib.Path(path).parent.name]for path in all_image_paths]\n","  paths_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n","  image_ds = paths_ds.map(load_and_preprocess_image)\n","  label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\n","\n","  return read_dataset(filename = '/content/model/eval.tfrec',#<-------\n","                      batch_size = eval_batch, \n","                      mode = tf.estimator.ModeKeys.EVAL,\n","                      image = image_ds,\n","                      label = label_ds)\n","\n","def serving_input_fn():\n","  json_feature_placeholders = {'image' : tf.placeholder(tf.float32, [None]),}\n","  features = json_feature_placeholders\n","  return tf.estimator.export.ServingInputReceiver(features, json_feature_placeholders)\n","\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"VbGjQ33fJeXj","colab_type":"text"},"cell_type":"markdown","source":["# Modelo\n","**Configuracion del modelo importado**"]},{"metadata":{"id":"cOCKkRZx8pPr","colab_type":"code","colab":{}},"cell_type":"code","source":["def model_fn(features, labels, mode, params):\n","  #module = hub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_050_192/feature_vector/2\")\n","  #module = hub.Module(\"https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/1\")\n","  tfh_module=tfhub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2\")\n","  transformed_features = tfh_module(features)\n","  logits = tf.layers.dense(transformed_features, 2) #<-------\n","  probabilities = tf.nn.softmax(logits)\n","  \n","  if (mode != tf.estimator.ModeKeys.PREDICT):\n","    one_hot_labels = tf.one_hot(labels, 2) #<-------\n","    loss = tf.losses.softmax_cross_entropy(one_hot_labels, logits)\n","    optimizer = tf.train.AdamOptimizer() \n","    train_op = tf.contrib.training.create_train_op(loss, optimizer)\n","    accuracy = tf.metrics.accuracy(labels, tf.argmax(probabilities, axis=-1))\n","    metrics = {'acc':accuracy}\n","  else:\n","    # None of these can be computed in prediction mode because labels are not available\n","    loss = optimizer = train_op = metrics = None\n","  \n","  return tf.estimator.EstimatorSpec(\n","      mode=mode,\n","      loss=loss,\n","      train_op=train_op,\n","      # Nice: in estimator, you can return computed results that are not part of model training (here: class)\n","      predictions={'proba': probabilities, 'class': tf.argmax(probabilities, axis=-1)},\n","      eval_metric_ops=metrics\n","  )"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WPlZsHN78MEl","colab_type":"text"},"cell_type":"markdown","source":["# Entrenamiento"]},{"metadata":{"id":"wmkUyMDqJhHO","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_and_evaluate(): #args\n","  # Estimador del modelo a usar\n","  run_config = tf.estimator.RunConfig(\n","    model_dir = path_trained) #args['output_dir'],  Ouput directory for checkpoint\n","    #save_summary_steps = summary_steps, \n","    #save_checkpoints_steps = steps_per_epoch, #, save_checkpoints_step = 100\n","    #log_step_count_steps=log_step)\n","\n","  # Define los aspectos del modelo # ojo aqui esta el transfer learning\n","  model = tf.estimator.Estimator(\n","    model_fn = model_fn,\n","    config = run_config)\n","\n","  # Define los aspectos del entrenamiento y la entrada de datos\n","  train_spec = tf.estimator.TrainSpec(\n","    input_fn = train_input_fn, \n","    max_steps = train_steps) #args['train_steps']\n","\n","  # Define los aspectos del uso en produccion con ML Engine\n","  export_latest = tf.estimator.LatestExporter(\n","    'exporter', #folder to export\n","    serving_input_receiver_fn = serving_input_fn)\n","\n","  # Define los aspectos de la evaluacion, cada cuanto se graba para tensorboard y la entrada de datos\n","  eval_spec = tf.estimator.EvalSpec(\n","    input_fn = eval_input_fn)\n","    #steps = None,\n","    #start_delay_secs = eval_delay_secs, # args['eval_delay_secs'] start evaluating after N seconds\n","    #throttle_secs = throttle_secs) #, args['throttle_secs'] evaluate every N seconds\n","    #exporters = export_latest)\n","\n","  # Ejecuta el modelo\n","  out = tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n","  return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xo64AqHiBKOm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":2714},"outputId":"68a9877b-7946-4a52-9463-81c0dc09d505","executionInfo":{"status":"ok","timestamp":1556423724671,"user_tz":300,"elapsed":47787,"user":{"displayName":"Hernán Lopez Archila","photoUrl":"https://lh4.googleusercontent.com/-notp8jonoeY/AAAAAAAAAAI/AAAAAAAAfV4/x2JEFyvg6TM/s64/photo.jpg","userId":"11762393844550192215"}}},"cell_type":"code","source":["import shutil \n","shutil.rmtree('/content/model/trained', ignore_errors=False, onerror=None)\n","\n","trained_model = train_and_evaluate()"],"execution_count":80,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': '/content/model/trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb89280e438>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:43.112519 140433646442368 estimator.py:201] Using config: {'_model_dir': '/content/model/trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb89280e438>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7fb8d1407d90>) includes params argument, but params are not passed to Estimator.\n"],"name":"stdout"},{"output_type":"stream","text":["W0428 03:54:43.115835 140433646442368 estimator.py:1924] Estimator's model_fn (<function model_fn at 0x7fb8d1407d90>) includes params argument, but params are not passed to Estimator.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Not using Distribute Coordinator.\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:43.119558 140433646442368 estimator_training.py:185] Not using Distribute Coordinator.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:43.122730 140433646442368 training.py:610] Running training and evaluation locally (non-distributed).\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:43.126111 140433646442368 training.py:698] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:43.750717 140433646442368 estimator.py:1111] Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:46.775640 140433646442368 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:47.066599 140433646442368 estimator.py:1113] Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Create CheckpointSaverHook.\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:47.072098 140433646442368 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:47.781192 140433646442368 monitored_session.py:222] Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:48.661817 140433646442368 session_manager.py:491] Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:48.761857 140433646442368 session_manager.py:493] Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 0 into /content/model/trained/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:52.769286 140433646442368 basic_session_run_hooks.py:594] Saving checkpoints for 0 into /content/model/trained/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.67089134, step = 0\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:54.104205 140433646442368 basic_session_run_hooks.py:249] loss = 0.67089134, step = 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 67.3572\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:55.588258 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 67.3572\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.0024149031, step = 100 (1.497 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:55.601033 140433646442368 basic_session_run_hooks.py:247] loss = 0.0024149031, step = 100 (1.497 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 82.4468\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:56.801148 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 82.4468\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.0034382134, step = 200 (1.211 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:56.811630 140433646442368 basic_session_run_hooks.py:247] loss = 0.0034382134, step = 200 (1.211 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 82.9954\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:58.006040 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 82.9954\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.0066223056, step = 300 (1.213 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:58.024912 140433646442368 basic_session_run_hooks.py:247] loss = 0.0066223056, step = 300 (1.213 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 82.9898\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:59.211009 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 82.9898\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.03986663, step = 400 (1.195 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:54:59.219701 140433646442368 basic_session_run_hooks.py:247] loss = 0.03986663, step = 400 (1.195 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 83.1501\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:00.413656 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 83.1501\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.001284299, step = 500 (1.200 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:00.419394 140433646442368 basic_session_run_hooks.py:247] loss = 0.001284299, step = 500 (1.200 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 83.5822\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:01.610095 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 83.5822\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.18446568, step = 600 (1.204 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:01.623445 140433646442368 basic_session_run_hooks.py:247] loss = 0.18446568, step = 600 (1.204 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 93.5189\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:02.679385 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 93.5189\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.00011878923, step = 700 (1.064 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:02.687666 140433646442368 basic_session_run_hooks.py:247] loss = 0.00011878923, step = 700 (1.064 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 92.1046\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:03.765095 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 92.1046\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.031057965, step = 800 (1.084 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:03.772094 140433646442368 basic_session_run_hooks.py:247] loss = 0.031057965, step = 800 (1.084 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 92.5341\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:04.845809 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 92.5341\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.0006937451, step = 900 (1.084 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:04.855885 140433646442368 basic_session_run_hooks.py:247] loss = 0.0006937451, step = 900 (1.084 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 89.4599\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:05.963629 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 89.4599\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.000189611, step = 1000 (1.120 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:05.975858 140433646442368 basic_session_run_hooks.py:247] loss = 0.000189611, step = 1000 (1.120 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 90.7704\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:07.065280 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 90.7704\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.00039257342, step = 1100 (1.092 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:07.068069 140433646442368 basic_session_run_hooks.py:247] loss = 0.00039257342, step = 1100 (1.092 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 89.0652\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:08.188053 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 89.0652\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.0003757276, step = 1200 (1.124 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:08.192081 140433646442368 basic_session_run_hooks.py:247] loss = 0.0003757276, step = 1200 (1.124 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 92.5411\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:09.268650 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 92.5411\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.003243796, step = 1300 (1.084 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:09.275641 140433646442368 basic_session_run_hooks.py:247] loss = 0.003243796, step = 1300 (1.084 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 89.8847\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:10.381189 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 89.8847\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.008475684, step = 1400 (1.117 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:10.392524 140433646442368 basic_session_run_hooks.py:247] loss = 0.008475684, step = 1400 (1.117 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 91.575\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:11.473217 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 91.575\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.00020177689, step = 1500 (1.085 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:11.477156 140433646442368 basic_session_run_hooks.py:247] loss = 0.00020177689, step = 1500 (1.085 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 89.1007\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:12.595530 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 89.1007\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.0006242336, step = 1600 (1.128 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:12.605052 140433646442368 basic_session_run_hooks.py:247] loss = 0.0006242336, step = 1600 (1.128 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 90.6161\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:13.699057 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 90.6161\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.00045297877, step = 1700 (1.102 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:13.707473 140433646442368 basic_session_run_hooks.py:247] loss = 0.00045297877, step = 1700 (1.102 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 91.7983\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:14.788423 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 91.7983\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.00045781312, step = 1800 (1.085 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:14.792827 140433646442368 basic_session_run_hooks.py:247] loss = 0.00045781312, step = 1800 (1.085 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 91.2\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:15.884945 140433646442368 basic_session_run_hooks.py:680] global_step/sec: 91.2\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.026306953, step = 1900 (1.096 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:15.889258 140433646442368 basic_session_run_hooks.py:247] loss = 0.026306953, step = 1900 (1.096 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 2000 into /content/model/trained/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:16.965749 140433646442368 basic_session_run_hooks.py:594] Saving checkpoints for 2000 into /content/model/trained/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:17.585762 140433646442368 estimator.py:1111] Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:20.827215 140433646442368 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:21.114304 140433646442368 estimator.py:1113] Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2019-04-28T03:55:21Z\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:21.139767 140433646442368 evaluation.py:257] Starting evaluation at 2019-04-28T03:55:21Z\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:21.847308 140433646442368 monitored_session.py:222] Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /content/model/trained/model.ckpt-2000\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:21.858048 140433646442368 saver.py:1270] Restoring parameters from /content/model/trained/model.ckpt-2000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:22.462495 140433646442368 session_manager.py:491] Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:22.546775 140433646442368 session_manager.py:493] Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [10/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:23.191047 140433646442368 evaluation.py:169] Evaluation [10/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [20/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:23.311003 140433646442368 evaluation.py:169] Evaluation [20/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [30/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:23.422769 140433646442368 evaluation.py:169] Evaluation [30/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [40/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:23.533849 140433646442368 evaluation.py:169] Evaluation [40/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [50/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:23.649989 140433646442368 evaluation.py:169] Evaluation [50/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [60/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:23.764510 140433646442368 evaluation.py:169] Evaluation [60/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [70/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:23.876084 140433646442368 evaluation.py:169] Evaluation [70/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [80/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:23.985982 140433646442368 evaluation.py:169] Evaluation [80/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [90/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:24.100095 140433646442368 evaluation.py:169] Evaluation [90/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [100/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:24.209266 140433646442368 evaluation.py:169] Evaluation [100/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2019-04-28-03:55:24\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:24.371357 140433646442368 evaluation.py:277] Finished evaluation at 2019-04-28-03:55:24\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 2000: acc = 0.99, global_step = 2000, loss = 0.036414064\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:24.373376 140433646442368 estimator.py:1979] Saving dict for global step 2000: acc = 0.99, global_step = 2000, loss = 0.036414064\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: /content/model/trained/model.ckpt-2000\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:24.382121 140433646442368 estimator.py:2039] Saving 'checkpoint_path' summary for global step 2000: /content/model/trained/model.ckpt-2000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Loss for final step: 0.0064928057.\n"],"name":"stdout"},{"output_type":"stream","text":["I0428 03:55:24.471757 140433646442368 estimator.py:359] Loss for final step: 0.0064928057.\n"],"name":"stderr"}]},{"metadata":{"id":"YFF7-jqoiJk7","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}