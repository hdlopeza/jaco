{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MILE.Imagenes4,1","version":"0.3.2","provenance":[],"collapsed_sections":["VbGjQ33fJeXj","WPlZsHN78MEl"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"C7WTKdnOCTBr","colab_type":"code","colab":{}},"source":["import os\n","import pathlib\n","import random\n","import tensorflow as tf\n","import tensorflow_hub as tfhub\n","#tf.enable_eager_execution()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pJjqwNTU9igJ","colab_type":"code","colab":{}},"source":["AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","train_steps = 500 # Modelo Train\n","summary_steps = 100 # 100 Modelo Train\n","steps_per_epoch = 100 # Modelo Train\n","log_step = 10 # Modelo Train\n","train_batch_size = 5 # Funciones de input train y eval\n","BATCH_SIZE = 5 # dataset buffer y batch\n","eval_delay_secs = 10 # 10 Modelo Eval\n","throttle_secs = 30 # 30 Modelo Eval"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xndr4SoKCoKg","colab_type":"code","outputId":"9fb0585a-62c0-4084-9f86-4a270c7b65fc","executionInfo":{"status":"ok","timestamp":1556829630412,"user_tz":300,"elapsed":532,"user":{"displayName":"Hern√°n Lopez Archila","photoUrl":"https://lh4.googleusercontent.com/-notp8jonoeY/AAAAAAAAAAI/AAAAAAAAfV4/x2JEFyvg6TM/s64/photo.jpg","userId":"11762393844550192215"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["tf.logging.info('TF Version {}'.format(tf.__version__))\n","tf.logging.info('GPU Available {}'.format(tf.test.is_gpu_available()))\n","if 'TF_CONFIG' in os.environ:\n","    tf.logging.info('TF_CONFIG: {}'.format(os.environ[\"TF_CONFIG\"]))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:TF Version 1.13.1\n"],"name":"stdout"},{"output_type":"stream","text":["I0502 20:40:30.253412 140276394538880 <ipython-input-25-33f139de6631>:1] TF Version 1.13.1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:GPU Available True\n"],"name":"stdout"},{"output_type":"stream","text":["I0502 20:40:30.262027 140276394538880 <ipython-input-25-33f139de6631>:2] GPU Available True\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"OfMTFRQebwpW","colab_type":"text"},"source":["**Rutas**"]},{"cell_type":"code","metadata":{"id":"cTvGHTsPbrhc","colab_type":"code","colab":{}},"source":["# Modelo general\n","path_model = '/content/model/'\n","os.makedirs(os.path.join(path_model), exist_ok=True)\n","\n","# Modelo entrenado\n","path_trained = os.path.join(path_model, 'trained')\n","\n","# Modelo importado\n","TFHUB_CACHE_DIR = os.path.join(path_model, 'TFHub')\n","os.environ['TFHUB_CACHE_DIR'] = TFHUB_CACHE_DIR\n","\n","# Data importada\n","path_data = os.path.join(path_model, 'dogscats')\n","url_data = 'http://files.fast.ai/data/dogscats.zip'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rsPvpfSzr8Jc","colab_type":"text"},"source":["# Modelo importado\n","**Importacion**"]},{"cell_type":"code","metadata":{"id":"JQ6RhpC7Gstu","colab_type":"code","cellView":"code","colab":{}},"source":["#if not os.path.isdir(os.path.join(path_model, 'TFHub')):\n","  classifier_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2\" #@param {type:\"string\"}\n","  tfh_module = tfhub.Module(classifier_url)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eGIOpZtKb84r","colab_type":"text"},"source":["**Variables derivadas**"]},{"cell_type":"code","metadata":{"id":"tP5Oje0_cB1r","colab_type":"code","colab":{}},"source":["IMAGE_SIZE = tfhub.get_expected_image_size(tfh_module)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bUGN4GRzQUWL","colab_type":"text"},"source":["import shutil\n","shutil.rmtree('/content/model/trained', ignore_errors=False, onerror=None)"]},{"cell_type":"markdown","metadata":{"id":"aogVdxjNiFJf","colab_type":"text"},"source":["# Tensorboard"]},{"cell_type":"code","metadata":{"id":"FIaxEiwkiJ1O","colab_type":"code","colab":{}},"source":["def run_tftb():\n"," !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n"," !unzip ngrok-stable-linux-amd64.zip\n","\n"," LOG_DIR = path_trained\n"," get_ipython().system_raw(\n","     'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","     .format(LOG_DIR))\n"," \n"," get_ipython().system_raw('./ngrok http 6006 &')\n"," \n"," !curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","     \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n","#run_tftb()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XQuX7HjGsE0A","colab_type":"text"},"source":["# Datos\n"]},{"cell_type":"markdown","metadata":{"id":"__uDH3mWgzqe","colab_type":"text"},"source":["## Adquisicion"]},{"cell_type":"code","metadata":{"id":"Ts23GW9aC5U6","colab_type":"code","colab":{}},"source":["if not os.path.isdir(path_data):\n","  tf.keras.utils.get_file(fname = os.path.basename(url_data), origin = url_data, \n","                          cache_subdir=path_model, extract=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0-7uql7brwyV","colab_type":"text"},"source":["**Directorios de datos**"]},{"cell_type":"code","metadata":{"id":"jzq0-cW9seeY","colab_type":"code","colab":{}},"source":["train_path = os.path.join(path_data, 'train')\n","eval_path = os.path.join(path_data, 'valid')\n","pred_path = os.path.join(path_data, 'sample', 'train')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SAB72Jo4t61e","colab_type":"text"},"source":["---\n","For this output, you can connect additional layers according to the problem you want to solve. For example, if the problem is to classify images into 10 categories, you may want to continue fully connected-layer with 10 nodes, and apply the softmax function to have the probabilities.\n","\n","\n","logits = tf.layers.dense(inputs=outputs, units=10)\n","predictions = {\n","    \"classes\": tf.argmax(input=logits, axis=1),\n","    \"probabilities\": tf.nn.softmax(logits)\n","}\n","\n","---\n","train_input_fn = tf.data.Dataset.list_files(train_files)\n","\n","---\n","label = tf.string_split(source = [train_files], delimiter = '/').values[-2]\n","\n","---\n","from IPython.core.debugger import Tracer; Tracer()() \n","n, c, q"]},{"cell_type":"markdown","metadata":{"id":"Rf4wvxQnrtJF","colab_type":"text"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"id":"0pehMuFNwI_m","colab_type":"code","colab":{}},"source":["def preprocess_image(image):\n","  image = tf.image.decode_jpeg(image, channels=3) #<-------\n","  image = tf.image.resize(image, IMAGE_SIZE) #<-------\n","  image /= 255.0  # normalize to [0,1] range #<-------\n","  return image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ULil4K9wN-r","colab_type":"code","colab":{}},"source":["def load_and_preprocess_image(path):\n","  image = tf.read_file(path)\n","  return preprocess_image(image)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BgIrBdPSKisJ","colab_type":"code","colab":{}},"source":["def read_dataset(filename, tfr_file, mode, batch_size):  \n","\n","  data_root = pathlib.Path(filename)#<------- filename\n","  all_image_paths = list(data_root.glob('*/*'))\n","  all_image_paths = [str(path) for path in all_image_paths]\n","  random.shuffle(all_image_paths)\n","\n","  #if not os.path.isfile(tfr_file):    #<------- tfr_file\n","  #  paths_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n","  #  image_ds = paths_ds.map(load_and_preprocess_image)\n","  #  ds = image_ds.map(tf.serialize_tensor) \n","  #  tfrec = tf.data.experimental.TFRecordWriter(tfr_file)#<------- tfr_file\n","  #  tfrec.write(ds)\n","\n","  #Toma la ruta de las imagenes, la decodifica, crea el tensor de atributos\n","  #ds = tf.data.TFRecordDataset(tfr_file)\n","  #def parse(x):\n","  #  result = tf.parse_tensor(x, out_type=tf.float32)\n","  #  result = tf.reshape(result, [224, 224, 3]) #<-------\n","  #  return result\n","  #ds = ds.map(parse, num_parallel_calls=AUTOTUNE)\n","  \n","  #Como mejorar estas lineas\n","  label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n","  label_to_index = dict((name, index) for index,name in enumerate(label_names))\n","  all_image_labels = [label_to_index[pathlib.Path(path).parent.name] for path in all_image_paths]\n","  paths_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n","  image_ds = paths_ds.map(load_and_preprocess_image)\n","  label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\n","  \n","  ds = tf.data.Dataset.zip((image_ds, label_ds)) #<-------\n","  \n","  if mode == tf.estimator.ModeKeys.TRAIN:\n","    num_epochs = None #Loop indefinidamente\n","    ds = ds.shuffle(buffer_size = batch_size) # video 7:10 https://www.youtube.com/watch?v=uIcqeP7MFH0\n","    ds = ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=batch_size*10)) #image_count\n","  else:\n","    num_epochs = 1 #end-of-input after this\n","  \n","  ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE) # video 7:48\n","  return ds"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vBcgwKmDK1aC","colab_type":"code","colab":{}},"source":["def train_input_fn():\n","  return read_dataset(filename = train_path,#<-------\n","                      tfr_file = '/content/model/train.tfrec',\n","                      batch_size = train_batch_size, \n","                      mode = tf.estimator.ModeKeys.TRAIN)\n","\n","def eval_input_fn():\n","  return read_dataset(filename = eval_path,#<-------\n","                      tfr_file = '/content/model/eval.tfrec',\n","                      batch_size = train_batch_size, \n","                      mode = tf.estimator.ModeKeys.EVAL)\n","\n","def pred_input_fn():\n","  return read_dataset(filename = pred_path,#<------- \n","                      tfr_file = '/content/model/pred.tfrec',\n","                      batch_size = train_batch_size, \n","                      mode = tf.estimator.ModeKeys.PREDICT)\n","\n","def serving_input_fn():\n","  json_feature_placeholders = {'images' : tf.placeholder(tf.float32, shape=(None, 224, 224, 3))} #<--- puede ser shape(None)\n","  features = json_feature_placeholders\n","  return tf.estimator.export.ServingInputReceiver(features, json_feature_placeholders)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VbGjQ33fJeXj","colab_type":"text"},"source":["# Modelo\n","**Configuracion del modelo importado**"]},{"cell_type":"code","metadata":{"id":"cOCKkRZx8pPr","colab_type":"code","colab":{}},"source":["def model_fn(features, labels, mode, params):\n","  #module = hub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_050_192/feature_vector/2\")\n","  #module = hub.Module(\"https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/1\")\n","  tfh_module=tfhub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2\")\n","  transformed_features = tfh_module(features)\n","  logits = tf.layers.dense(transformed_features, 2) #<-------\n","  probabilities = tf.nn.softmax(logits)\n","  \n","  if (mode != tf.estimator.ModeKeys.PREDICT):\n","    one_hot_labels = tf.one_hot(labels, 2) #<-------\n","    loss = tf.losses.softmax_cross_entropy(one_hot_labels, logits)\n","    optimizer = tf.train.AdamOptimizer() \n","    train_op = tf.contrib.training.create_train_op(loss, optimizer)\n","    accuracy = tf.metrics.accuracy(labels, tf.argmax(probabilities, axis=-1))\n","    metrics = {'acc':accuracy}\n","  else:\n","    # None of these can be computed in prediction mode because labels are not available\n","    loss = optimizer = train_op = metrics = None\n","  \n","  return tf.estimator.EstimatorSpec(\n","      mode=mode,\n","      loss=loss,\n","      train_op=train_op,\n","      # Nice: in estimator, you can return computed results that are not part of model training (here: class)\n","      predictions={'proba': probabilities, 'class': tf.argmax(probabilities, axis=-1)},\n","      eval_metric_ops=metrics\n","  )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WPlZsHN78MEl","colab_type":"text"},"source":["# Entrenamiento"]},{"cell_type":"code","metadata":{"id":"wmkUyMDqJhHO","colab_type":"code","colab":{}},"source":["def train_and_evaluate(): #args\n","  # Estimador del modelo a usar\n","  run_config = tf.estimator.RunConfig(\n","    model_dir = path_trained, #args['output_dir'],  Ouput directory for checkpoint\n","    save_summary_steps = summary_steps, \n","    save_checkpoints_steps = steps_per_epoch, #, save_checkpoints_step = 100\n","    log_step_count_steps=log_step)\n","\n","  # Define los aspectos del modelo # ojo aqui esta el transfer learning\n","  model = tf.estimator.Estimator(\n","    model_fn = model_fn,\n","    config = run_config)\n","\n","  # Define los aspectos del entrenamiento y la entrada de datos\n","  train_spec = tf.estimator.TrainSpec(\n","    input_fn = train_input_fn, \n","    max_steps = train_steps) #args['train_steps']\n","\n","  # Define los aspectos del uso en produccion con ML Engine\n","  export_latest = tf.estimator.LatestExporter(\n","    'exporter', #folder to export\n","    serving_input_receiver_fn = serving_input_fn)\n","\n","  # Define los aspectos de la evaluacion, cada cuanto se graba para tensorboard y la entrada de datos\n","  eval_spec = tf.estimator.EvalSpec(\n","    input_fn = eval_input_fn,\n","    steps = None,\n","    start_delay_secs = eval_delay_secs, # args['eval_delay_secs'] start evaluating after N seconds\n","    throttle_secs = throttle_secs, #, args['throttle_secs'] evaluate every N seconds\n","    exporters = export_latest)\n","\n","  # Ejecuta el modelo\n","  out = tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n","  print(out)\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eRE4LnIuTNMD","colab_type":"text"},"source":["# Prediccion"]},{"cell_type":"code","metadata":{"id":"xo64AqHiBKOm","colab_type":"code","colab":{}},"source":["import shutil\n","if os.path.isdir('/content/model/trained'):\n","  shutil.rmtree('/content/model/trained', ignore_errors=False, onerror=None)\n","\n","trained_model = train_and_evaluate()\n","print(trained_model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Gi75PY1IjSL","colab_type":"code","colab":{}},"source":["predictions = trained_model.predict(input_fn = pred_input_fn)\n","for items in predictions:\n","    print(items)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IKq66EMEUxHg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}