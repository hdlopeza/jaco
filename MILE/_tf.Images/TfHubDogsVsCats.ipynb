{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copia de TfHubDogsVsCats.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/damienpontifex/BlogCodeSamples/blob/master/TransferLearning/TfHubDogsVsCats.ipynb","timestamp":1556079072942}],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"colab_type":"text","id":"yyrWPiiHyT2W"},"cell_type":"markdown","source":["# Image classification using TensorFlow estimators and TensorFlow Hub for transfer learning"]},{"metadata":{"colab_type":"text","id":"MImaq1-xzVPo"},"cell_type":"markdown","source":["*This notebook is available [as a codelab](https://colab.research.google.com/github/damienpontifex/BlogCodeSamples/blob/master/TransferLearning/TfHubDogsVsCats.ipynb)*"]},{"metadata":{"id":"XJYNh4Skih7-","colab_type":"text"},"cell_type":"markdown","source":["TensorFlow Hub was [announced](https://www.youtube.com/watch?v=rirzJ-e68cw) at TensorFlow Dev Summit 2018 and promises to reduce the effort required to use existing machine learning models and weights in your own custom model. From the [overview page](https://www.tensorflow.org/hub/)\n","\n","> TensorFlow Hub is a library to foster the publication, discovery, and consumption of reusable parts of machine learning models. A module is a self-contained piece of a TensorFlow graph, along with its weights and assets, that can be reused across different tasks in a process known as transfer learning.\n","\n","Dogs vs Cats is a great classification problem to learn about transfer learning and is the [first lesson of the fast.ai course](http://course.fast.ai/lessons/lesson1.html) and was hosted on Kaggle. The teaching is if you can achieve transfer learning for this two-class problem of cats and dogs, you can do it for any *n*-class problem for your own solution."]},{"metadata":{"id":"s3I7UkATih8B","colab_type":"text"},"cell_type":"markdown","source":["### Prerequisites"]},{"metadata":{"id":"EkKBCfrRih8D","colab_type":"text"},"cell_type":"markdown","source":["You will need to install TensorFlow Hub from pip and have at least TensorFlow version 1.7. I'm also assuming you have some understanding (although not required but will be in this code) of TensorFlow and machine learning, mainly:\n","* Data preparation\n","* tf.data input\n","* TensorFlow estimators\n","\n","To ensure you've got the libraries installed run:"]},{"metadata":{"id":"O5F7fiOQih8F","colab_type":"code","outputId":"b7ac4923-5542-4b3c-91a6-60ea89549648","colab":{}},"cell_type":"code","source":["%%bash \n","# pip3 install -qU tensorflow>=1.7.0 # Don't run this on Google's colab as you probably want to use the version they have pre-installed\n","python -m pip install -qU tensorflow-hub"],"execution_count":0,"outputs":[{"output_type":"stream","text":["kaggle 1.4.7.1 requires tqdm, which is not installed.\n","kaggle 1.4.7.1 has requirement urllib3<1.23.0,>=1.15, but you'll have urllib3 1.23 which is incompatible.\n","You are using pip version 10.0.1, however version 18.1 is available.\n","You should consider upgrading via the 'pip install --upgrade pip' command.\n"],"name":"stderr"}]},{"metadata":{"id":"JXBZrehlih8S","colab_type":"text"},"cell_type":"markdown","source":["Just some usual imports and matplotlib setup for notebooks. And then just print out some information about our TensorFlow environment"]},{"metadata":{"colab_type":"code","id":"xfWmW-C4yT2Z","colab":{}},"cell_type":"code","source":["import os\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","l = tf.keras.layers"],"execution_count":0,"outputs":[]},{"metadata":{"id":"33ektN9nih8Y","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"elapsed":3002,"status":"ok","timestamp":1524296794479,"user":{"displayName":"Damien Pontifex","photoUrl":"//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg","userId":"108154422920170673093"},"user_tz":-480},"id":"5CILIgB8yT2b","outputId":"61cbcfb8-9abc-44b3-9450-63e6755f146f","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["tf.logging.info('TF Version {}'.format(tf.__version__))\n","tf.logging.info('GPU Available {}'.format(tf.test.is_gpu_available()))\n","if 'TF_CONFIG' in os.environ:\n","    tf.logging.info('TF_CONFIG: {}'.format(os.environ[\"TF_CONFIG\"]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:TF Version 1.12.0\n","INFO:tensorflow:GPU Available False\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"uDKyHDlryT2Y"},"cell_type":"markdown","source":["The Dogs vs Cats Kaggle competition is a two-class image classification problem. Transfer learning can be used to reduce the amount of computation and to reuse previously computed features of interest.\n","\n","For this, we'll look into the new TensorFlow Hub modules to train on our own dataset. First lets just grab, and have a look, at the data we've got."]},{"metadata":{"colab_type":"text","id":"yBuHfgNEyT2g"},"cell_type":"markdown","source":["## Data\n","\n","We will get the data from the fastai zip of the dogs and cats images. The file pattern on disk is to have each category of images labelled by placing all associated images into one folder. As such, we will have a folder named 'dogs' of all dog images and 'cats' of all cat images to train on."]},{"metadata":{"colab_type":"text","id":"ZNCd9lh6yT2h"},"cell_type":"markdown","source":["So that this notebook can be run anywhere, here we are just downloading the archive and placing it in a temporary local data directory"]},{"metadata":{"colab_type":"code","id":"OkOoTig1yT2j","colab":{}},"cell_type":"code","source":["def get_data(local_data_root: str, is_chief: bool=True):\n","    data_dir = os.path.join(local_data_root, 'datasets/dogscats')\n","    \n","    if is_chief:\n","        if not tf.gfile.IsDirectory(data_dir):\n","            # Download the data zip to our data directory and extract\n","            fallback_url = 'http://files.fast.ai/data/dogscats.zip'\n","            tf.keras.utils.get_file(\n","                os.path.join(local_data_root, os.path.basename(fallback_url)), \n","                fallback_url, \n","                cache_dir=local_data_root,\n","                extract=True)\n","        \n","    return data_dir"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1ThNyAPTih8n","colab_type":"code","colab":{}},"cell_type":"code","source":["data_dir = get_data('/tmp', True)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"-5IESSdvyT2m"},"cell_type":"markdown","source":["Looking at what is in the data directory"]},{"metadata":{"colab_type":"code","id":"UCGH9FF3yT2n","colab":{}},"cell_type":"code","source":["tf.gfile.ListDirectory(data_dir)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"u8IaDYSI3Hwv"},"cell_type":"markdown","source":["Look in the valid directory to see the image classes. Here we see we have a folder of dogs and another of cats."]},{"metadata":{"colab_type":"code","id":"Q_p3NtYwyT2p","colab":{}},"cell_type":"code","source":["tf.gfile.ListDirectory(os.path.join(data_dir, 'valid'))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"4cucT-8nyT2r","colab":{}},"cell_type":"code","source":["cats = tf.gfile.ListDirectory(os.path.join(data_dir, 'valid', 'cats'))[:5]\n","cats"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mhvbZu7Dih8w","colab_type":"code","colab":{}},"cell_type":"code","source":["with tf.gfile.GFile(os.path.join(data_dir, 'valid', 'cats', cats[0]), 'rb') as f:\n","    img = plt.imread(f)\n","    plt.imshow(img)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"AJpkogZuyT20","colab":{}},"cell_type":"code","source":["img.shape"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"Fvc9MEvlyT22"},"cell_type":"markdown","source":["## tf.data to access our dataset"]},{"metadata":{"colab_type":"text","id":"Q0wBO0U3yT23"},"cell_type":"markdown","source":["Our dataset input function is responsible for providing features and labels to the network. We will use a glob pattern via the `file_pattern` parameter to indicate the files on disk and return a dataset to use."]},{"metadata":{"id":"Di4AOLT-ih81","colab_type":"code","colab":{}},"cell_type":"code","source":["def _img_string_to_tensor(image_string, image_size=(299, 299)):\n","    \"\"\"Decodes jpeg image bytes and resizes into float32 tensor\n","    \n","    Args:\n","      image_string: A Tensor of type string that has the image bytes\n","    \n","    Returns:\n","      float32 tensor of the image\n","    \"\"\"\n","    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n","    # Convert from full range of uint8 to range [0,1] of float32.\n","    image_decoded_as_float = tf.image.convert_image_dtype(image_decoded, dtype=tf.float32)\n","    # Resize to expected\n","    image_resized = tf.image.resize_images(image_decoded_as_float, size=image_size)\n","    \n","    return image_resized"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"1NNmeWQhyT23","colab":{}},"cell_type":"code","source":["def make_dataset(file_pattern, image_size=(299, 299), shuffle=False, batch_size=64, num_epochs=None, buffer_size=4096):\n","    \"\"\"Makes a dataset reading the input images given the file pattern\n","    \n","    Args:\n","      file_pattern: File pattern to match input files with\n","      image_size: size to resize images to\n","      shuffle: whether to shuffle the dataset\n","      batch_size: the batch size of the dataset\n","      num_epochs: number of times to repeat iteration of the dataset\n","      buffer_size: size of buffer for prefetch and shuffle operations\n","    \n","    Returns:\n","      A tf.data.Dataset with dictionary of key to Tensor for features and label Tensor of type string\n","    \"\"\"\n","    \n","    def _path_to_img(path):\n","        \"\"\"From the given path returns a feature dictionary and label pair\n","        \n","        Args:\n","          path: A Tensor of type string of the file path to read from\n","          \n","        Returns:\n","          Tuple of dict and tensor. \n","          Dictionary is key to tensor mapping of features\n","          Label is a Tensor of type string that is the label for these features\n","        \"\"\"\n","        # Get the parent folder of this file to get it's class name\n","        label = tf.string_split([path], delimiter='/').values[-2]\n","        \n","        # Read in the image from disk\n","        image_string = tf.io.read_file(path)\n","        image_resized = _img_string_to_tensor(image_string, image_size)\n","        \n","        return { 'image': image_resized }, label\n","    \n","    opt = tf.data.Options()\n","    opt.experimental_autotune = True\n","    opt.experimental_map_and_batch_fusion = True\n","    opt.experimental_shuffle_and_repeat_fusion = True\n","    \n","    dataset = tf.data.Dataset.list_files(file_pattern)\n","\n","    if shuffle:\n","        dataset = dataset.shuffle(buffer_size)\n","\n","    dataset = dataset.repeat(num_epochs)\n","    dataset = dataset.map(_path_to_img)\n","    dataset = dataset.batch(batch_size).prefetch(buffer_size)\n","\n","    dataset = dataset.with_options(opt)\n","\n","    return dataset"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"n6Es-6sjyT26"},"cell_type":"markdown","source":["## Our first model"]},{"metadata":{"colab_type":"text","id":"wRZKeml15-iW"},"cell_type":"markdown","source":["We're setting up an esimator `model_fn` so we can include the module as the base and then provide our own dense layer and activations to be trained for our use case. We're passing in the module spec (a string) via the `params` dictionary so we could swap out another image classification model easily.\n","\n","The highlight here for TensorFlow Hub and transfer learning are these lines:\n","\n","```python\n","module = hub.Module(params['module_spec'], trainable=is_training, name=params['module_name'])\n","bottleneck_tensor = module(features['image'])\n","```\n","\n","We load up the module and specify whether we would like to fine tune it or not. Then pass in our image tensor to the module and get the output tensor as `bottleneck_tensor` to be used in further layers. If you see a diagram of the structure of some of these models, the simplification of this down to two lines is amazing!"]},{"metadata":{"colab_type":"code","id":"FYAwIHlE4gfh","colab":{}},"cell_type":"code","source":["def model_fn(features, labels, mode, params):\n","    \"\"\"tf.estimator model function implementation for retraining an image classifier from a \n","    tf hub module\n","    \n","    Args:\n","      features: dictionary of key to Tensor\n","      labels: Tensor of type string\n","      mode: estimator mode\n","      params: dictionary of parameters\n","      \n","    Returns:\n","      tf.estimator.EstimatorSpec instance\n","    \"\"\"\n","    is_training = mode == tf.estimator.ModeKeys.TRAIN\n","    module_trainable = is_training and params.get('train_module', False)\n","\n","    module = hub.Module(params['module_spec'], trainable=module_trainable, name=params['module_name'])\n","    bottleneck_tensor = module(features['image'])\n","    \n","    NUM_CLASSES = len(params['label_vocab'])\n","    logit_units = 1 if NUM_CLASSES == 2 else NUM_CLASSES\n","    logits = l.Dense(logit_units)(bottleneck_tensor)\n","\n","    if NUM_CLASSES == 2:\n","        head = tf.contrib.estimator.binary_classification_head(label_vocabulary=params['label_vocab'])\n","    else:\n","        head = tf.contrib.estimator.multi_class_head(n_classes=NUM_CLASSES, label_vocabulary=params['label_vocab'])\n","\n","    optimizer = tf.train.AdamOptimizer(learning_rate=params.get('learning_rate', 1e-3))\n","    \n","    return head.create_estimator_spec(\n","        features, mode, logits, labels, optimizer=optimizer\n","    )"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jp0g1zSNih89","colab_type":"text"},"cell_type":"markdown","source":["Finally, we setup our estimator as per usual:\n","\n","* Define some hyperparameters\n","* Construct the estimator\n","* `train_and_evaluate`\n","\n","And with that, we get distributed training and great device placement for data processing on the CPU and training on the GPU."]},{"metadata":{"colab_type":"code","id":"fzrxTWnD9hBr","colab":{}},"cell_type":"code","source":["def train():\n","    \"\"\"Run training operation\n","    \"\"\"\n","    \n","    run_config = tf.estimator.RunConfig()\n","    \n","    data_directory = get_data('/tmp', run_config.is_chief)\n","    model_directory = '/tmp/dogscats/run2'\n","\n","    params = {\n","        'module_spec': 'https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/1',\n","        'module_name': 'resnet_v2_50',\n","        'learning_rate': 1e-3,\n","        'train_module': False,  # Whether we want to finetune the module\n","        'label_vocab': tf.gfile.ListDirectory(os.path.join(data_directory, 'valid'))\n","    }\n","\n","    classifier = tf.estimator.Estimator(\n","        model_fn=model_fn,\n","        model_dir=model_directory,\n","        config=run_config,\n","        params=params\n","    )\n","\n","    input_img_size = hub.get_expected_image_size(hub.Module(params['module_spec']))\n","\n","    train_files = os.path.join(data_directory, 'train', '**/*.jpg')\n","    train_input_fn = lambda: make_dataset(train_files, image_size=input_img_size, batch_size=8, shuffle=True)\n","    train_spec = tf.estimator.TrainSpec(train_input_fn, max_steps=30)\n","\n","    eval_files = os.path.join(data_directory, 'valid', '**/*.jpg')\n","    eval_input_fn = lambda: make_dataset(eval_files, image_size=input_img_size, batch_size=1)\n","    eval_spec = tf.estimator.EvalSpec(eval_input_fn)\n","\n","    tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"rYLgeNKc_SX_","scrolled":false,"colab":{}},"cell_type":"code","source":["train()"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"PlrHicQFKKYQ","colab":{}},"cell_type":"code","source":["## Conclusion"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8KDErA9dih9F","colab_type":"text"},"cell_type":"markdown","source":["TensorFlow Hub will significantely increase the approachability for people to use complex models from others for their own specific task. The ability to fine tune while also using as is continues to democritize everyone's use of ML tools."]},{"metadata":{"id":"sX-Gp1GAih9H","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}