{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MILE","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"metadata":{"id":"C7WTKdnOCTBr","colab_type":"code","outputId":"a068739f-6cb0-41ea-f249-864e41a79dd8","executionInfo":{"status":"ok","timestamp":1556398219406,"user_tz":300,"elapsed":1587,"user":{"displayName":"Hernán Lopez Archila","photoUrl":"https://lh4.googleusercontent.com/-notp8jonoeY/AAAAAAAAAAI/AAAAAAAAfV4/x2JEFyvg6TM/s64/photo.jpg","userId":"11762393844550192215"}},"colab":{"base_uri":"https://localhost:8080/","height":92}},"cell_type":"code","source":["import os\n","import pathlib\n","import random\n","import tensorflow as tf\n","import tensorflow_hub as tfhub"],"execution_count":1,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0427 20:50:19.899661 140229051844480 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"],"name":"stderr"}]},{"metadata":{"id":"pJjqwNTU9igJ","colab_type":"code","colab":{}},"cell_type":"code","source":["#Data\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","BATCH_SIZE = 5\n","epochs= 10\n","steps_per_epoch = 10\n","summary_steps = 10\n","\n","#Model\n","log_step = 10\n","train_batch_size = 5\n","eval_batch = 5\n","eval_delay_secs = 1 \n","throttle_secs = 1\n","train_steps = 1050"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Xndr4SoKCoKg","colab_type":"code","colab":{}},"cell_type":"code","source":["#tf.logging.info('TF Version {}'.format(tf.__version__))\n","#tf.logging.info('GPU Available {}'.format(tf.test.is_gpu_available()))\n","#if 'TF_CONFIG' in os.environ:\n","#    tf.logging.info('TF_CONFIG: {}'.format(os.environ[\"TF_CONFIG\"]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OfMTFRQebwpW","colab_type":"text"},"cell_type":"markdown","source":["**Rutas**"]},{"metadata":{"id":"cTvGHTsPbrhc","colab_type":"code","colab":{}},"cell_type":"code","source":["# Modelo general\n","path_model = './model/'\n","os.makedirs(os.path.join(path_model), exist_ok=True)\n","\n","# Modelo importado\n","TFHUB_CACHE_DIR = os.path.join(path_model, 'TFHub')\n","os.environ['TFHUB_CACHE_DIR'] = TFHUB_CACHE_DIR\n","\n","# Data importada\n","path_data = os.path.join(path_model, 'datasets')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rsPvpfSzr8Jc","colab_type":"text"},"cell_type":"markdown","source":["# Modelo importado\n","**Importacion**"]},{"metadata":{"id":"JQ6RhpC7Gstu","colab_type":"code","cellView":"code","colab":{}},"cell_type":"code","source":["classifier_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2\" #@param {type:\"string\"}\n","tfh_module = tfhub.Module(classifier_url)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eGIOpZtKb84r","colab_type":"text"},"cell_type":"markdown","source":["**Variables derivadas**"]},{"metadata":{"id":"tP5Oje0_cB1r","colab_type":"code","colab":{}},"cell_type":"code","source":["IMAGE_SIZE = tfhub.get_expected_image_size(tfh_module)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XQuX7HjGsE0A","colab_type":"text"},"cell_type":"markdown","source":["# Datos\n"]},{"metadata":{"id":"__uDH3mWgzqe","colab_type":"text"},"cell_type":"markdown","source":["## Adquisicion"]},{"metadata":{"id":"Ts23GW9aC5U6","colab_type":"code","colab":{}},"cell_type":"code","source":["url = 'http://files.fast.ai/data/dogscats.zip'\n","path_data = tf.keras.utils.get_file(fname = os.path.basename(url), \n","                                    origin = url, \n","                                    cache_dir=path_model,\n","                                    extract=True)\n","path_data = os.path.dirname(path_data)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0-7uql7brwyV","colab_type":"text"},"cell_type":"markdown","source":["**Directorios de datos**"]},{"metadata":{"id":"jzq0-cW9seeY","colab_type":"code","colab":{}},"cell_type":"code","source":["train_path = os.path.join(data_directory, 'train')\n","train_files = os.path.join(data_directory, 'train', '**/*.jpg')\n","eval_path = os.path.join(data_directory, 'valid')\n","eval_files = os.path.join(data_directory, 'valid', '**/*.jpg')\n","pred_path = os.path.join(data_directory, 'sample/train')\n","pred_files = os.path.join(data_directory, 'sample/train','**/*.jpg')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aG89825eYCFC","colab_type":"code","outputId":"15036bdc-2491-4dbf-a766-96e331bb98c0","executionInfo":{"status":"ok","timestamp":1556393388793,"user_tz":300,"elapsed":31161,"user":{"displayName":"Hernán Lopez Archila","photoUrl":"https://lh4.googleusercontent.com/-notp8jonoeY/AAAAAAAAAAI/AAAAAAAAfV4/x2JEFyvg6TM/s64/photo.jpg","userId":"11762393844550192215"}},"colab":{"base_uri":"https://localhost:8080/","height":440}},"cell_type":"code","source":["pred_image = list(pathlib.Path(pred_path).glob('*/*'))\n","pred_image"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[PosixPath('/tmp/datasets/dogscats/sample/train/cats/cat.4600.jpg'),\n"," PosixPath('/tmp/datasets/dogscats/sample/train/cats/cat.3570.jpg'),\n"," PosixPath('/tmp/datasets/dogscats/sample/train/cats/cat.4865.jpg'),\n"," PosixPath('/tmp/datasets/dogscats/sample/train/cats/cat.11737.jpg'),\n"," PosixPath('/tmp/datasets/dogscats/sample/train/cats/cat.394.jpg'),\n"," PosixPath('/tmp/datasets/dogscats/sample/train/cats/cat.2921.jpg'),\n"," PosixPath('/tmp/datasets/dogscats/sample/train/cats/cat.2266.jpg'),\n"," PosixPath('/tmp/datasets/dogscats/sample/train/cats/cat.9021.jpg'),\n"," PosixPath('/tmp/datasets/dogscats/sample/train/dogs/dog.8091.jpg'),\n"," PosixPath('/tmp/datasets/dogscats/sample/train/dogs/dog.8643.jpg'),\n"," PosixPath('/tmp/datasets/dogscats/sample/train/dogs/dog.9077.jpg'),\n"," PosixPath('/tmp/datasets/dogscats/sample/train/dogs/dog.1614.jpg'),\n"," PosixPath('/tmp/datasets/dogscats/sample/train/dogs/dog.6768.jpg'),\n"," PosixPath('/tmp/datasets/dogscats/sample/train/dogs/dog.2423.jpg'),\n"," PosixPath('/tmp/datasets/dogscats/sample/train/dogs/dog.1402.jpg'),\n"," PosixPath('/tmp/datasets/dogscats/sample/train/dogs/dog.6391.jpg')]"]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"id":"NE8dmhmgMBi-","colab_type":"code","colab":{}},"cell_type":"code","source":["data_root = pathlib.Path(train_path)\n","all_image_paths = list(data_root.glob('*/*'))\n","all_image_paths = [str(path) for path in all_image_paths]\n","random.shuffle(all_image_paths)\n","\n","label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n","label_to_index = dict((name, index) for index,name in enumerate(label_names))\n","all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n","                  for path in all_image_paths]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SAB72Jo4t61e","colab_type":"text"},"cell_type":"markdown","source":["---\n","For this output, you can connect additional layers according to the problem you want to solve. For example, if the problem is to classify images into 10 categories, you may want to continue fully connected-layer with 10 nodes, and apply the softmax function to have the probabilities.\n","\n","\n","logits = tf.layers.dense(inputs=outputs, units=10)\n","predictions = {\n","    \"classes\": tf.argmax(input=logits, axis=1),\n","    \"probabilities\": tf.nn.softmax(logits)\n","}\n","\n","---\n","train_input_fn = tf.data.Dataset.list_files(train_files)\n","\n","---\n","label = tf.string_split(source = [train_files], delimiter = '/').values[-2]\n","\n","---\n","from IPython.core.debugger import Tracer; Tracer()() \n","n, c, q"]},{"metadata":{"id":"Rf4wvxQnrtJF","colab_type":"text"},"cell_type":"markdown","source":["# Dataset"]},{"metadata":{"id":"BgIrBdPSKisJ","colab_type":"code","colab":{}},"cell_type":"code","source":["def read_dataset(filename, mode, batch_size):\n","  \n","  #Creacion de la ruta de las imagenes\n","  data_root = pathlib.Path(filename)\n","  all_image_paths = list(data_root.glob('*/*'))\n","  all_image_paths = [str(path) for path in all_image_paths]\n","  random.shuffle(all_image_paths)\n","  \n","  label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n","  label_to_index = dict((name, index) for index,name in enumerate(label_names))\n","  all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n","                    for path in all_image_paths]\n","  \n","  #Decodificar y cambiar el size de la imagen\n","  def _load_and_preprocess_image(path):\n","  #def _input_fn():\n","    def _preprocess_image(image):\n","      image = tf.image.decode_jpeg(image, channels=3)\n","      image = tf.image.resize(image, IMAGE_SIZE)\n","      image /= 255.9 # se esta normalizando a [0, 1]\n","      return image\n","\n","    image_encoded = tf.read_file(path)\n","    image_decoded = _preprocess_image(image_encoded)\n","\n","    return image_decoded\n","  #return _input_fn\n","  \n","  #Toma la ruta de las imagenes, la decodifica, crea el tensor de atributos\n","  paths_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n","  image_ds = paths_ds.map(_load_and_preprocess_image)\n","  label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\n","  image_count = len(all_image_paths)\n","  \n","\n","  ds = tf.data.Dataset.zip((image_ds, label_ds))\n","  \n","  if mode == tf.estimator.ModeKeys.TRAIN:\n","    num_epochs = None #Loop indefinidamente\n","    ds = ds.shuffle(buffer_size = batch_size) # video 7:10 https://www.youtube.com/watch?v=uIcqeP7MFH0\n","    ds = ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=10*batch_size)) #10*batch_size -- image_count\n","  else:\n","    num_epochs = 1 #end-of-input after this\n","  \n","  ds = ds.repeat(epochs).batch(BATCH_SIZE).prefetch(AUTOTUNE) # video 7:48\n","  return ds.make_one_shot_iterator().get_next()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vBcgwKmDK1aC","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_input_fn():\n","    return read_dataset(\n","        filename = train_path, #args['train_data_paths']\n","        batch_size = train_batch_size, #args['train_batch_size']\n","        mode = tf.estimator.ModeKeys.TRAIN)\n","\n","def eval_input_fn():\n","  return read_dataset(\n","      filename = eval_path, #args['eval_data_paths']\n","      batch_size = eval_batch, \n","      mode = tf.estimator.ModeKeys.EVAL)\n","\n","def pred_input_fn():\n","  return read_dataset(\n","      filename = pred_path,\n","      batch_size = eval_batch, \n","      mode = tf.estimator.ModeKeys.PRED)\n","\n","def serving_input_fn():\n","  json_feature_placeholders = {\n","    'image' : tf.placeholder(tf.float32, [None]),}\n","  features = json_feature_placeholders\n","  return tf.estimator.export.ServingInputReceiver(features, json_feature_placeholders)\n","\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"VbGjQ33fJeXj","colab_type":"text"},"cell_type":"markdown","source":["# Modelo\n","**Configuracion del modelo importado**"]},{"metadata":{"id":"cOCKkRZx8pPr","colab_type":"code","colab":{}},"cell_type":"code","source":["def model_fn(features, labels, mode, params):\n","  #module = hub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_050_192/feature_vector/2\")\n","  #module = hub.Module(\"https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/1\")\n","  tfh_module=tfhub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2\")\n","  transformed_features = tfh_module(features)\n","  logits = tf.layers.dense(transformed_features, len(label_names))\n","  probabilities = tf.nn.softmax(logits)\n","  \n","  if (mode != tf.estimator.ModeKeys.PREDICT):\n","    one_hot_labels = tf.one_hot(labels, len(label_names))\n","    loss = tf.losses.softmax_cross_entropy(one_hot_labels, logits)\n","    optimizer = tf.train.AdamOptimizer() \n","    train_op = tf.contrib.training.create_train_op(loss, optimizer)\n","    accuracy = tf.metrics.accuracy(labels, tf.argmax(probabilities, axis=-1))\n","    metrics = {'acc':accuracy}\n","  else:\n","    # None of these can be computed in prediction mode because labels are not available\n","    loss = optimizer = train_op = metrics = None\n","  \n","  return tf.estimator.EstimatorSpec(\n","      mode=mode,\n","      loss=loss,\n","      train_op=train_op,\n","      # Nice: in estimator, you can return computed results that are not part of model training (here: class)\n","      predictions={'proba': probabilities, 'class': tf.argmax(probabilities, axis=-1)},\n","      eval_metric_ops=metrics\n","  )"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WPlZsHN78MEl","colab_type":"text"},"cell_type":"markdown","source":["# Entrenamiento"]},{"metadata":{"id":"wmkUyMDqJhHO","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_and_evaluate(): #args\n","  #% 3 Estimador del modelo a usar\n","  run_config = tf.estimator.RunConfig(\n","    model_dir = \"/tmp\") #args['output_dir'],  Ouput directory for checkpoint\n","    #save_summary_steps = summary_steps, \n","    #save_checkpoints_steps = steps_per_epoch, #, save_checkpoints_step = 100\n","    #log_step_count_steps=log_step)\n","\n","  # Define los aspectos del modelo # ojo aqui esta el transfer learning\n","  model = tf.estimator.Estimator(\n","    model_fn = model_fn,\n","    config = run_config)\n","\n","  # Define los aspectos del entrenamiento y la entrada de datos\n","  train_spec = tf.estimator.TrainSpec(\n","    input_fn = train_input_fn, \n","    max_steps = train_steps) #args['train_steps']\n","\n","  # Define los aspectos del uso en produccion con ML Engine\n","  export_latest = tf.estimator.LatestExporter(\n","    'exporter', #folder to export\n","    serving_input_receiver_fn = serving_input_fn)\n","\n","  # Define los aspectos de la evaluacion, cada cuanto se graba para tensorboard y la entrada de datos\n","  eval_spec = tf.estimator.EvalSpec(\n","    input_fn = eval_input_fn)\n","    #steps = None,\n","    #start_delay_secs = eval_delay_secs, # args['eval_delay_secs'] start evaluating after N seconds\n","    #throttle_secs = throttle_secs) #, args['throttle_secs'] evaluate every N seconds\n","    #exporters = export_latest)\n","\n","  # Ejecuta el modelo\n","  out = tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n","  return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xo64AqHiBKOm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":2695},"outputId":"4c152057-b3e7-4ae0-eeae-e879eb8ac0cb","executionInfo":{"status":"ok","timestamp":1556393686064,"user_tz":300,"elapsed":328377,"user":{"displayName":"Hernán Lopez Archila","photoUrl":"https://lh4.googleusercontent.com/-notp8jonoeY/AAAAAAAAAAI/AAAAAAAAfV4/x2JEFyvg6TM/s64/photo.jpg","userId":"11762393844550192215"}}},"cell_type":"code","source":["trained_model = train_and_evaluate()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': '/tmp', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7feb5484b6a0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:29:48.851213 140649632647040 estimator.py:201] Using config: {'_model_dir': '/tmp', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7feb5484b6a0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7feb5484d730>) includes params argument, but params are not passed to Estimator.\n"],"name":"stdout"},{"output_type":"stream","text":["W0427 19:29:48.855255 140649632647040 estimator.py:1924] Estimator's model_fn (<function model_fn at 0x7feb5484d730>) includes params argument, but params are not passed to Estimator.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Not using Distribute Coordinator.\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:29:48.859803 140649632647040 estimator_training.py:185] Not using Distribute Coordinator.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:29:48.862148 140649632647040 training.py:610] Running training and evaluation locally (non-distributed).\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:29:48.864316 140649632647040 training.py:698] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:29:49.556759 140649632647040 estimator.py:1111] Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:29:52.897396 140649632647040 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-12-a71737d6bec8>:6: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n"],"name":"stdout"},{"output_type":"stream","text":["W0427 19:29:53.016998 140649632647040 deprecation.py:323] From <ipython-input-12-a71737d6bec8>:6: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"stream","text":["W0427 19:29:53.097583 140649632647040 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:29:55.977248 140649632647040 estimator.py:1113] Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Create CheckpointSaverHook.\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:29:55.982718 140649632647040 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:29:57.633005 140649632647040 monitored_session.py:222] Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:29:58.710396 140649632647040 session_manager.py:491] Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:29:58.838387 140649632647040 session_manager.py:493] Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 0 into /tmp/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:30:03.156784 140649632647040 basic_session_run_hooks.py:594] Saving checkpoints for 0 into /tmp/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 1.0238285, step = 1\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:30:04.903573 140649632647040 basic_session_run_hooks.py:249] loss = 1.0238285, step = 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 4.15891\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:30:28.947853 140649632647040 basic_session_run_hooks.py:680] global_step/sec: 4.15891\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.009001, step = 101 (24.048 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:30:28.951597 140649632647040 basic_session_run_hooks.py:247] loss = 0.009001, step = 101 (24.048 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 4.26398\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:30:52.400125 140649632647040 basic_session_run_hooks.py:680] global_step/sec: 4.26398\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.059523124, step = 201 (23.452 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:30:52.403498 140649632647040 basic_session_run_hooks.py:247] loss = 0.059523124, step = 201 (23.452 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 4.16861\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:31:16.388930 140649632647040 basic_session_run_hooks.py:680] global_step/sec: 4.16861\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.0023201916, step = 301 (23.989 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:31:16.392580 140649632647040 basic_session_run_hooks.py:247] loss = 0.0023201916, step = 301 (23.989 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 4.18283\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:31:40.296215 140649632647040 basic_session_run_hooks.py:680] global_step/sec: 4.18283\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.02349431, step = 401 (23.907 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:31:40.299873 140649632647040 basic_session_run_hooks.py:247] loss = 0.02349431, step = 401 (23.907 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 4.24466\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:32:03.855208 140649632647040 basic_session_run_hooks.py:680] global_step/sec: 4.24466\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.0011283901, step = 501 (23.563 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:32:03.863008 140649632647040 basic_session_run_hooks.py:247] loss = 0.0011283901, step = 501 (23.563 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 4.23337\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:32:27.477044 140649632647040 basic_session_run_hooks.py:680] global_step/sec: 4.23337\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.00020225966, step = 601 (23.618 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:32:27.480942 140649632647040 basic_session_run_hooks.py:247] loss = 0.00020225966, step = 601 (23.618 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 4.23032\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:32:51.115917 140649632647040 basic_session_run_hooks.py:680] global_step/sec: 4.23032\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.002828212, step = 701 (23.644 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:32:51.125108 140649632647040 basic_session_run_hooks.py:247] loss = 0.002828212, step = 701 (23.644 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 4.21507\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:33:14.840324 140649632647040 basic_session_run_hooks.py:680] global_step/sec: 4.21507\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.00044014872, step = 801 (23.720 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:33:14.844623 140649632647040 basic_session_run_hooks.py:247] loss = 0.00044014872, step = 801 (23.720 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 4.25625\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:33:38.335224 140649632647040 basic_session_run_hooks.py:680] global_step/sec: 4.25625\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.0020934446, step = 901 (23.495 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:33:38.339464 140649632647040 basic_session_run_hooks.py:247] loss = 0.0020934446, step = 901 (23.495 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 4.23215\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:01.963882 140649632647040 basic_session_run_hooks.py:680] global_step/sec: 4.23215\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.0032399371, step = 1001 (23.628 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:01.967785 140649632647040 basic_session_run_hooks.py:247] loss = 0.0032399371, step = 1001 (23.628 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 1050 into /tmp/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:13.661335 140649632647040 basic_session_run_hooks.py:594] Saving checkpoints for 1050 into /tmp/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:14.311462 140649632647040 estimator.py:1111] Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:17.888061 140649632647040 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:18.201674 140649632647040 estimator.py:1113] Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2019-04-27T19:34:18Z\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:18.230863 140649632647040 evaluation.py:257] Starting evaluation at 2019-04-27T19:34:18Z\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:18.998342 140649632647040 monitored_session.py:222] Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n"],"name":"stdout"},{"output_type":"stream","text":["W0427 19:34:19.001201 140649632647040 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /tmp/model.ckpt-1050\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:19.015669 140649632647040 saver.py:1270] Restoring parameters from /tmp/model.ckpt-1050\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:19.609646 140649632647040 session_manager.py:491] Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:19.733404 140649632647040 session_manager.py:493] Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [10/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:22.651999 140649632647040 evaluation.py:169] Evaluation [10/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [20/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:25.032059 140649632647040 evaluation.py:169] Evaluation [20/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [30/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:27.409940 140649632647040 evaluation.py:169] Evaluation [30/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [40/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:29.800738 140649632647040 evaluation.py:169] Evaluation [40/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [50/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:32.189366 140649632647040 evaluation.py:169] Evaluation [50/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [60/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:34.568527 140649632647040 evaluation.py:169] Evaluation [60/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [70/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:36.942539 140649632647040 evaluation.py:169] Evaluation [70/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [80/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:39.299504 140649632647040 evaluation.py:169] Evaluation [80/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [90/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:41.695291 140649632647040 evaluation.py:169] Evaluation [90/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Evaluation [100/100]\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:44.075649 140649632647040 evaluation.py:169] Evaluation [100/100]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2019-04-27-19:34:44\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:44.276473 140649632647040 evaluation.py:277] Finished evaluation at 2019-04-27-19:34:44\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 1050: acc = 0.986, global_step = 1050, loss = 0.032039676\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:44.281251 140649632647040 estimator.py:1979] Saving dict for global step 1050: acc = 0.986, global_step = 1050, loss = 0.032039676\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1050: /tmp/model.ckpt-1050\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:45.327067 140649632647040 estimator.py:2039] Saving 'checkpoint_path' summary for global step 1050: /tmp/model.ckpt-1050\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Loss for final step: 0.1457856.\n"],"name":"stdout"},{"output_type":"stream","text":["I0427 19:34:45.409554 140649632647040 estimator.py:359] Loss for final step: 0.1457856.\n"],"name":"stderr"}]},{"metadata":{"id":"YFF7-jqoiJk7","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}