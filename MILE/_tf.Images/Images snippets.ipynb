{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Snippets.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"LqVVhEqA9zOm","colab_type":"text"},"cell_type":"markdown","source":["## v1\n","Ver MILE"]},{"metadata":{"id":"P9ChY051s9kS","colab_type":"text"},"cell_type":"markdown","source":["**Creacion de los atributos, labels o etiquetas de clasificacion de cada imagen**"]},{"metadata":{"id":"Wr1hZWfAsuF_","colab_type":"code","colab":{}},"cell_type":"code","source":["label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n","label_to_index = dict((name, index) for index,name in enumerate(label_names))\n","all_image_labels = [label_to_index[pathlib.Path(path).parent.name] for path in all_image_paths]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cnmx4ULDyeAF","colab_type":"text"},"cell_type":"markdown","source":["**Creacion del dataset que inyecta los datos al modelo**"]},{"metadata":{"id":"s1DoeK64yJM9","colab_type":"code","colab":{}},"cell_type":"code","source":["tfds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ovzfnXui0KFP","colab_type":"text"},"cell_type":"markdown","source":["**Pre-procesar la imagen convirtiendola a algo que el modelo pueda entender**"]},{"metadata":{"id":"vsBwdcdD1zbJ","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_and_preprocess_from_path_label(path, label):\n","  #def _input_fn():\n","    def _preprocess_image(image):\n","      image = tf.image.decode_jpeg(image, channels=3)\n","      image = tf.image.resize(image, IMAGE_SIZE)\n","      image /= 255.9 # se esta normalizando a [0, 1]\n","      return image\n","      \n","    image_encoded = tf.read_file(path)\n","    image_decoded = _preprocess_image(image_encoded)\n","     \n","    return image_decoded, label\n","  #return _input_fn"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W8V8HRAT5_2H","colab_type":"code","outputId":"eefef32e-0b4d-45d4-c344-ec989ebbce9a","executionInfo":{"status":"ok","timestamp":1556254003580,"user_tz":300,"elapsed":574,"user":{"displayName":"Hern√°n Lopez Archila","photoUrl":"https://lh4.googleusercontent.com/-notp8jonoeY/AAAAAAAAAAI/AAAAAAAAfV4/x2JEFyvg6TM/s64/photo.jpg","userId":"11762393844550192215"}},"colab":{"base_uri":"https://localhost:8080/","height":32}},"cell_type":"code","source":["image_label_ds = tfds.map(load_and_preprocess_from_path_label)\n","image_label_ds"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<DatasetV1Adapter shapes: ((224, 224, 3), ()), types: (tf.float32, tf.int32)>"]},"metadata":{"tags":[]},"execution_count":32}]},{"metadata":{"id":"sRRiWWMvGe49","colab_type":"code","colab":{}},"cell_type":"code","source":["# Setting a shuffle buffer size as large as the dataset ensures that the data is\n","# completely shuffled.\n","ds = image_label_ds.shuffle(buffer_size=image_count)\n","ds = ds.repeat()\n","ds = ds.batch(BATCH_SIZE)\n","# `prefetch` lets the dataset fetch batches, in the background while the model is training.\n","ds = ds.prefetch(buffer_size=AUTOTUNE)\n","ds"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yUTvXBNvGzIE","colab_type":"code","colab":{}},"cell_type":"code","source":["ds = image_label_ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n","ds = ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n","ds"],"execution_count":0,"outputs":[]},{"metadata":{"id":"660p1jN11wfB","colab_type":"text"},"cell_type":"markdown","source":["Dataset"]},{"metadata":{"id":"z5zy81eN1wLh","colab_type":"code","colab":{}},"cell_type":"code","source":["def read_dataset(filename, mode, batch_size):\n","  \n","  #Creacion de la ruta de las imagenes\n","  data_root = pathlib.Path(filename)\n","  all_image_paths = list(data_root.glob('*/*'))\n","  all_image_paths = [str(path) for path in all_image_paths]\n","  random.shuffle(all_image_paths)\n","  \n","  label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n","  label_to_index = dict((name, index) for index,name in enumerate(label_names))\n","  all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n","                    for path in all_image_paths]\n","  \n","  \n","  \n","  #Decodificar y cambiar el size de la imagen\n","  def _load_and_preprocess_image(path):\n","  #def _input_fn():\n","    def _preprocess_image(image):\n","      image = tf.image.decode_jpeg(image, channels=3)\n","      image = tf.image.resize(image, IMAGE_SIZE)\n","      image /= 255.9 # se esta normalizando a [0, 1]\n","      return image\n","\n","    image_encoded = tf.read_file(path)\n","    image_decoded = _preprocess_image(image_encoded)\n","\n","    return image_decoded\n","  #return _input_fn\n","  \n","  #Toma la ruta de las imagenes, la decodifica, crea el tensor de atributos\n","  paths_ds = tf.data.Dataset.from_tensor_slices(all_image_paths) \n","  image_ds = paths_ds.map(_load_and_preprocess_image)\n","  \n","  # se crea un TFRecord para mejorar la eficiencia\n","  ds = image_ds.map(tf.serialize_tensor)\n","  tfrec = tf.data.experimental.TFRecordWriter('images.tfrec')\n","  tfrec.write(ds)\n","  \n","  ## With the preprocessing cached, data can be loaded from the TFrecord file quite efficiently. \n","  ##Just remember to de-serialized tensor before trying to use it.\n","  ds = tf.data.TFRecordDataset('images.tfrec')\n","  def parse(x):\n","    result = tf.parse_tensor(x, out_type=tf.float32)\n","    result = tf.reshape(result, [*IMAGE_SIZE, 3])\n","    return result\n","  ds = ds.map(parse, num_parallel_calls=AUTOTUNE)\n","  \n","  label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\n","  image_count = len(all_image_paths)\n","  \n","  #Se ingest el dataset\n","  ds = tf.data.Dataset.zip((ds, label_ds))\n","  \n","  if mode == tf.estimator.ModeKeys.TRAIN:\n","    num_epochs = None #Loop indefinidamente\n","    ds = ds.shuffle(buffer_size = 10 * batch_size) # video 7:10 https://www.youtube.com/watch?v=uIcqeP7MFH0\n","    ds = ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=10*batch_size)) #image_count\n","  else:\n","    num_epochs = 1 #end-of-input after this\n","  \n","  ds = ds.repeat(epochs).batch(BATCH_SIZE).prefetch(AUTOTUNE) # video 7:48\n","  return ds.make_one_shot_iterator().get_next()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ooC83KG6Qn3s","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"DfvfhwZzIpfr","colab_type":"text"},"cell_type":"markdown","source":["# Predicciones"]},{"metadata":{"id":"28X5hlt6Vhgc","colab_type":"code","colab":{}},"cell_type":"code","source":["AUTO = tf.data.experimental.AUTOTUNE\n","from matplotlib import pyplot as plt\n","CLASSES = ['dogs', 'cats'] # do not change, maps to the labels in the data (folder names)\n","\n","def dataset_to_numpy_util(dataset, N):\n","  dataset = dataset.batch(N)\n","  #from IPython.core.debugger import Tracer; Tracer()() \n","  if tf.executing_eagerly():\n","    # In eager mode, iterate in the Datset directly.\n","    for images, labels in dataset:\n","      numpy_images = images.numpy()\n","      numpy_labels = labels.numpy()\n","      break;\n","      \n","  else: # In non-eager mode, must get the TF note that \n","        # yields the nextitem and run it in a tf.Session.\n","    get_next_item = dataset.make_one_shot_iterator().get_next()\n","    with tf.Session() as ses:\n","      numpy_images, numpy_labels = ses.run(get_next_item)\n","\n","  return numpy_images, numpy_labels\n","\n","def read_tfrecord(example):\n","    features = {\n","        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n","        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means scalar\n","    }\n","    example = tf.parse_single_example(example, features)\n","    image = tf.image.decode_jpeg(example['image'], channels=3)\n","    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n","    image = tf.reshape(image, [229, 229, 3]) # explicit size will be needed for TPU\n","    class_label = example['class']\n","    return image, class_label\n","\n","\n","def load_dataset(filenames):\n","  # read from TFRecords. For optimal performance, use \"interleave(tf.data.TFRecordDataset, ...)\"\n","  # to read from multiple TFRecord files at once and set the option experimental_deterministic = False\n","  # to allow order-altering optimizations.\n","\n","  option_no_order = tf.data.Options()\n","  option_no_order.experimental_deterministic = False\n","\n","  dataset = tf.data.Dataset.list_files(filenames)\n","  dataset = dataset.with_options(option_no_order)\n","  #dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=16)\n","  dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=16, num_parallel_calls=AUTO) # faster\n","  dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n","  return dataset\n","\n","def display_9_images_from_dataset(dataset):\n","  subplot=331\n","  plt.figure(figsize=(13,13))\n","  images, labels = dataset_to_numpy_util(dataset, 9)\n","  for i, image in enumerate(images):\n","    title = CLASSES[labels[i]]\n","    subplot = display_one_flower(image, title, subplot)\n","    if i >= 8:\n","      break;\n","              \n","  plt.tight_layout()\n","  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n","  plt.show()\n","\n","  \n","#display_9_images_from_dataset(load_dataset(pred_files))\n","#dataset_to_numpy_util(load_dataset(pred_files),9)\n","for images, labels in load_dataset('/tmp/datasets/dogscats/sample/train/cats/cat.4600.jpg'):\n","  numpy_images = images.numpy()\n","  numpy_labels = labels.numpy()"],"execution_count":0,"outputs":[]}]}