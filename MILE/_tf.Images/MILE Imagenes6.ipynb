{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MILE.Imagenes5","version":"0.3.2","provenance":[],"collapsed_sections":["VbGjQ33fJeXj","WPlZsHN78MEl"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"C7WTKdnOCTBr","colab_type":"code","colab":{}},"source":["import os\n","import pathlib\n","import random\n","import tensorflow as tf\n","import tensorflow_hub as tfhub\n","#tf.enable_eager_execution()\n","from IPython.core.debugger import Tracer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pJjqwNTU9igJ","colab_type":"code","colab":{}},"source":["AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","train_steps = 150 # 500 Modelo Train\n","summary_steps = 50 # 100 Modelo Train\n","steps_per_epoch = 100 # 100 Modelo Train\n","log_step = 10 # 10 Modelo Train\n","train_batch = 5 # 5 512 Funciones de input train\n","eval_batch = 5 # 5 500 Funciones de input eval\n","eval_delay_secs = 10 # 10 Modelo Eval\n","throttle_secs = 30 # 30 Modelo Eval\n","CLASSES = 2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xndr4SoKCoKg","colab_type":"code","colab":{}},"source":["tf.logging.info('TF Version {}'.format(tf.__version__))\n","tf.logging.info('GPU Available {}'.format(tf.test.is_gpu_available()))\n","if 'TF_CONFIG' in os.environ:\n","    tf.logging.info('TF_CONFIG: {}'.format(os.environ[\"TF_CONFIG\"]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OfMTFRQebwpW","colab_type":"text"},"source":["**Rutas**"]},{"cell_type":"code","metadata":{"id":"cTvGHTsPbrhc","colab_type":"code","colab":{}},"source":["# Modelo general\n","path_model = 'model/' #<--- en mac 'model/' en colab '/model/'\n","os.makedirs(os.path.join(path_model), exist_ok=True)\n","\n","# Modelo entrenado\n","path_trained = os.path.join(path_model, 'trained')\n","os.makedirs(path_trained, exist_ok=True)\n","\n","# Modelo importado\n","TFHUB_CACHE_DIR = os.path.join(path_model, 'TFHub')\n","os.environ['TFHUB_CACHE_DIR'] = TFHUB_CACHE_DIR\n","#os.makedirs(TFHUB_CACHE_DIR, exist_ok=True)\n","\n","# Data importada\n","path_data = os.path.join(path_model, 'data')\n","os.makedirs(path_data, exist_ok=True)\n","#url_data = 'http://files.fast.ai/data/dogscats.zip'\n","#if not os.path.isdir(path_data): tf.keras.utils.get_file(fname = os.path.basename(url_data), origin = url_data, cache_subdir=path_model, extract=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rsPvpfSzr8Jc","colab_type":"text"},"source":["# Modelo importado\n","**Importacion**"]},{"cell_type":"code","metadata":{"id":"JQ6RhpC7Gstu","colab_type":"code","cellView":"code","colab":{}},"source":["if not os.path.isdir(TFHUB_CACHE_DIR):\n","  tfh_module = tfhub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2\")\n","  #tfh_module = hub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_050_192/feature_vector/2\")\n","  #tfh_module = hub.Module(\"https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/1\")\n","  #tfh_module = tfhub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2\")\n","else:\n","  tfh_module = tfhub.Module(os.path.join(TFHUB_CACHE_DIR, 'adfe0cf8d843e3588bfb9602e32a718b12212904'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eGIOpZtKb84r","colab_type":"text"},"source":["**Variables derivadas**"]},{"cell_type":"code","metadata":{"id":"tP5Oje0_cB1r","colab_type":"code","colab":{}},"source":["IMAGE_SIZE = tfhub.get_expected_image_size(tfh_module)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XQuX7HjGsE0A","colab_type":"text"},"source":["# Datos\n"]},{"cell_type":"markdown","metadata":{"id":"0-7uql7brwyV","colab_type":"text"},"source":["**Directorios de datos**"]},{"cell_type":"code","metadata":{"id":"jzq0-cW9seeY","colab_type":"code","colab":{}},"source":["train_path = os.path.join(path_data, 'train')\n","eval_path = os.path.join(path_data, 'eval')\n","pred_path = os.path.join(path_data, 'pred/valid')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SAB72Jo4t61e","colab_type":"text"},"source":["---\n","For this output, you can connect additional layers according to the problem you want to solve. For example, if the problem is to classify images into 10 categories, you may want to continue fully connected-layer with 10 nodes, and apply the softmax function to have the probabilities.\n","\n","\n","logits = tf.layers.dense(inputs=outputs, units=10)\n","predictions = {\n","    \"classes\": tf.argmax(input=logits, axis=1),\n","    \"probabilities\": tf.nn.softmax(logits)\n","}\n","\n","---\n","train_input_fn = tf.data.Dataset.list_files(train_files)\n","\n","---\n","from IPython.core.debugger import Tracer; Tracer()() \n","n, c, q"]},{"cell_type":"markdown","metadata":{"id":"Rf4wvxQnrtJF","colab_type":"text"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"id":"-ULil4K9wN-r","colab_type":"code","colab":{}},"source":["def load_and_preprocess_image(path):\n","  \n","  image = tf.read_file(path)\n","  image = tf.image.decode_jpeg(image, channels=3) #<-------\n","  image = tf.image.resize(image, IMAGE_SIZE) #<-------\n","  image /= 255.0  # normalize to [0,1] range #<-------\n","  return image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BgIrBdPSKisJ","colab_type":"code","colab":{}},"source":["def read_dataset(filename, mode, batch_size):  \n","\n","  data_root = pathlib.Path(filename)#<------- filename\n","  all_image_paths = list(data_root.glob('*/*'))\n","  all_image_paths = [str(path) for path in all_image_paths]\n","  random.shuffle(all_image_paths) #<---- super importante para el desempeno del modelo\n","\n","  #Como mejorar estas lineas\n","  label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n","  label_to_index = dict((name, index) for index, name in enumerate(label_names))\n","  all_image_labels = [label_to_index[pathlib.Path(path).parent.name] for path in all_image_paths]\n","  paths_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n","  image_ds = paths_ds.map(load_and_preprocess_image)\n","  label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\n","  \n","  ds = tf.data.Dataset.zip((image_ds, label_ds)) #<-------\n","  \n","  if mode == tf.estimator.ModeKeys.TRAIN:\n","    num_epochs = None #Loop indefinidamente\n","    ds = ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=batch_size*10)) # video 7:10 https://www.youtube.com/watch?v=uIcqeP7MFH0\n","  else:\n","    num_epochs = 1 #end-of-input after this\n","  \n","  ds = ds.batch(batch_size).repeat(num_epochs).prefetch(AUTOTUNE) # video 7:48 .repeat(num_epochs) \n","  return ds"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fQwxpO9Pudy6","colab_type":"text"},"source":["## Funciones de entrada"]},{"cell_type":"code","metadata":{"id":"vBcgwKmDK1aC","colab_type":"code","colab":{}},"source":["def train_input_fn():\n","  return read_dataset(filename = train_path,#<-------\n","                      batch_size = train_batch, \n","                      mode = tf.estimator.ModeKeys.TRAIN)\n","\n","def eval_input_fn():\n","  return read_dataset(filename = eval_path,#<-------\n","                      batch_size = eval_batch, \n","                      mode = tf.estimator.ModeKeys.EVAL)\n","\n","def pred_input_fn():\n","  return read_dataset(filename = pred_path,#<------- \n","                      batch_size = train_batch,  #<---- No va en prediccion\n","                      mode = tf.estimator.ModeKeys.PREDICT)\n","\n","def serving_input_fn():\n","  json = {'images' : tf.placeholder(tf.string, [None])} #<--- puede ser shape=(None, 224, 224, 3)\n","\n","  def decode(jpeg):\n","    pixels = tf.image.decode_jpeg(jpeg, channels=3)\n","    return pixels\n","  \n","  pics = tf.map_fn(decode, json['images'], dtype=tf.float32)\n","  features = {'images': pics}\n","  return tf.estimator.export.ServingInputReceiver(features, json)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VbGjQ33fJeXj","colab_type":"text"},"source":["# Modelo\n","**Configuracion del modelo importado**"]},{"cell_type":"code","metadata":{"id":"cOCKkRZx8pPr","colab_type":"code","colab":{}},"source":["def model_fn(features, labels, mode, params):\n","  tfh_module=tfhub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2\")\n","  transformed_features = tfh_module(features)\n","  logits = tf.layers.dense(transformed_features, CLASSES) #<-------\n","  probabilities = tf.nn.softmax(logits)\n","  \n","  if (mode != tf.estimator.ModeKeys.PREDICT):\n","    one_hot_labels = tf.one_hot(labels, CLASSES) #<-------\n","    loss = tf.losses.softmax_cross_entropy(one_hot_labels, logits)\n","    optimizer = tf.train.AdamOptimizer() \n","    train_op = tf.contrib.training.create_train_op(loss, optimizer)\n","    accuracy = tf.metrics.accuracy(labels, tf.argmax(probabilities, axis=-1))\n","    metrics = {'acc':accuracy}\n","  else:\n","    # None of these can be computed in prediction mode because labels are not available\n","    loss = optimizer = train_op = metrics = None\n","  \n","  return tf.estimator.EstimatorSpec(\n","      mode=mode,\n","      loss=loss,\n","      train_op=train_op,\n","      # Nice: in estimator, you can return computed results that are not part of model training (here: class)\n","      predictions={'proba': probabilities, 'class': tf.argmax(probabilities, axis=-1)},\n","      eval_metric_ops=metrics\n","  )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WPlZsHN78MEl","colab_type":"text"},"source":["# Entrenamiento"]},{"cell_type":"code","metadata":{"id":"wmkUyMDqJhHO","colab_type":"code","colab":{}},"source":["def train_and_evaluate(): #args\n","  # Estimador del modelo a usar\n","  run_config = tf.estimator.RunConfig(\n","    model_dir = path_trained, #args['output_dir'],  Ouput directory for checkpoint\n","    save_summary_steps = summary_steps, \n","    save_checkpoints_steps = steps_per_epoch, #, save_checkpoints_step = 100\n","    log_step_count_steps=log_step)\n","\n","  # Define los aspectos del modelo # ojo aqui esta el transfer learning\n","  model = tf.estimator.Estimator(\n","    model_fn = model_fn,\n","    config = run_config)\n","\n","  # Define los aspectos del entrenamiento y la entrada de datos\n","  train_spec = tf.estimator.TrainSpec(\n","    input_fn = train_input_fn, \n","    max_steps = train_steps) #args['train_steps']\n","\n","  # Define los aspectos del uso en produccion con ML Engine\n","  export_latest = tf.estimator.LatestExporter(\n","    'exporter', #folder to export\n","    serving_input_receiver_fn = serving_input_fn)\n","\n","  # Define los aspectos de la evaluacion, cada cuanto se graba para tensorboard y la entrada de datos\n","  eval_spec = tf.estimator.EvalSpec(\n","    input_fn = eval_input_fn,\n","    steps = None,\n","    start_delay_secs = eval_delay_secs, # args['eval_delay_secs'] start evaluating after N seconds\n","    throttle_secs = throttle_secs, #, args['throttle_secs'] evaluate every N seconds\n","    exporters = export_latest)\n","\n","  # Ejecuta el modelo\n","  out = tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n","  print(out)\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eRE4LnIuTNMD","colab_type":"text"},"source":["# Prediccion"]},{"cell_type":"code","metadata":{"id":"xo64AqHiBKOm","colab_type":"code","colab":{}},"source":["import shutil\n","if os.path.isdir(path_trained):\n","  shutil.rmtree(path_trained, ignore_errors=False, onerror=None)\n","\n","trained_model = train_and_evaluate()\n","print(trained_model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Gi75PY1IjSL","colab_type":"code","colab":{}},"source":["predictions = trained_model.predict(input_fn = pred_input_fn)\n","for items in predictions:\n","    print(items)"],"execution_count":0,"outputs":[]}]}