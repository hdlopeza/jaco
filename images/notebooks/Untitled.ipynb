{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.TFRecordDataset('/data/invoices_train.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for element in ds.take(1):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecords(tensor_string):\n",
    "    \"\"\" \n",
    "    Decode a serialized tensor\n",
    "    That takes a image_dicts normalize and returns a tuple (x,y)\n",
    "    Returns a x(image) to decode\n",
    "    \"\"\"\n",
    "    feature_decode = {\n",
    "        'image_raw': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64, default_value=0)}\n",
    "\n",
    "    img_dic = tf.io.parse_single_example(tensor_string, feature_decode)\n",
    "    \n",
    "    label = img_dic['label']\n",
    "    image = tf.io.parse_tensor(serialized=img_dic[\"image_raw\"], out_type=tf.uint8)\n",
    "\n",
    "    return {'image': image, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: {image: <unknown>, label: ()}, types: {image: tf.uint8, label: tf.int64}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1 = ds.map(parse_tfrecords)\n",
    "ds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  ...\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]]\n",
      "\n",
      " [[255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  ...\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]]\n",
      "\n",
      " [[255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  ...\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  ...\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]]\n",
      "\n",
      " [[255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  ...\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]]\n",
      "\n",
      " [[255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  ...\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]]], shape=(224, 224, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for element in ds1.take(1):\n",
    "    print(tf.image.resize_images(element['image'], [224, 224]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((150528,), ()), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_data(image_dic):\n",
    "    \"\"\"  \n",
    "    Function that takes a image_dic, normalized (divided by 255) and returns a tupe (x, y)\n",
    "    \"\"\"\n",
    "\n",
    "    image, label = image_dic['image'], image_dic['label']\n",
    "    \n",
    "    image.set_shape([None, None, None])\n",
    "    #image = tf.image.decode_jpeg(image)\n",
    "    image = tf.math.divide(image, 255)\n",
    "    image = tf.image.resize_images(image, (224, 224))\n",
    "    image = tf.reshape(image, [224*224*3])\n",
    "\n",
    "    return (image, label)\n",
    "\n",
    "ds2 = ds1.map(preprocess_data)\n",
    "ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=259, shape=(150528,), dtype=float32, numpy=array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)>, <tf.Tensor: id=260, shape=(), dtype=int64, numpy=67>)\n"
     ]
    }
   ],
   "source": [
    "for element in ds2.take(1):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(224*224*3,), name='Hiraganas')\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
    "x = tf.keras.layers.BatchNormalization(renorm=True)(x)\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization(renorm=True)(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "# \"sparse me sirve para clasificacion mutuamente excluyente un label --- multilabel\"\n",
    "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = ds2.shuffle(buffer_size=30000).batch(32)\n",
    "ds2 = ds2.batch(64)\n",
    "history = model.fit(ds2, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
