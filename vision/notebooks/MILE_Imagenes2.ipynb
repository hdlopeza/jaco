{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ydQP-640TOPn"
   },
   "source": [
    "# Paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vKJKiQevTOPo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tfhub\n",
    "\n",
    "import time\n",
    "import split_folders #pip install split-folders -- https://github.com/jfilter/split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0SxvLk1hTOPs"
   },
   "outputs": [],
   "source": [
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QF6XQ6QUTOPu"
   },
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hvxU5qLbTOPv"
   },
   "outputs": [],
   "source": [
    "# Modelo importado\n",
    "TFHUB_CACHE_DIR = './models/tfhub'\n",
    "#os.environ['TFHUB_CACHE_DIR'] = TFHUB_CACHE_DIR\n",
    "#os.makedirs(TFHUB_CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# Ruta donde estan los archivos\n",
    "data_path = pathlib.Path('/Users/hdla/Documents/Proyectos/ML/MILE_data/imagesclassified')\n",
    "train_path = pathlib.Path('/Users/hdla/Downloads/data/train')\n",
    "test_path = pathlib.Path('/Users/hdla/Downloads/data/test')\n",
    "val_path = pathlib.Path('/Users/hdla/Downloads/data/val')\n",
    "\n",
    "# Divide la informacion de la carpeta dev en train-test-val\n",
    "split_folders.ratio(data_path, output='/Users/hdla/Downloads/data/', seed=1337, ratio=(.8, .1, .1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PwWfQvqyTOPx"
   },
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R6L5W5sCTOPy"
   },
   "source": [
    "Organizacion de features and labels. Las facturas se encuentran clasificadas en carpetas por cada nit de proveedor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Bik17pVTOPz",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def list_feature_label(path):\n",
    "    # Ruta de las facturas\n",
    "    facturas_root = [str(_) for _ in list(path.glob('*/*'))]\n",
    "\n",
    "    # maestro proveedores(nit)\n",
    "    proveedores = [_.name for _ in path.glob('*/')]\n",
    "\n",
    "    # maestro Proveedores(nit) con indice\n",
    "    proveedores_index = dict((_, idx) for idx,_ in enumerate(proveedores))\n",
    "\n",
    "    # Listado del indice en orden de cada factura\n",
    "    facturas_label = [proveedores_index[pathlib.Path(_).parent.name] for _ in facturas_root]\n",
    "    \n",
    "    return facturas_root, facturas_label\n",
    "\n",
    "features_train, labels_train = list_feature_label(train_path)\n",
    "features_test, labels_test = list_feature_label(test_path)\n",
    "features_val, labels_val = list_feature_label(train_path)\n",
    "features_main = [_.name for _ in data_path.glob('*/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "izPT_XtcTOP1"
   },
   "outputs": [],
   "source": [
    "#plt.display(plt.Image(facturas[369]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ih4OykvXTOP4"
   },
   "source": [
    "Importacion del modulo de transfer learning para imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4VDF2GgLTOP4"
   },
   "outputs": [],
   "source": [
    "def transfer_model():\n",
    "    if not os.path.isdir(TFHUB_CACHE_DIR):\n",
    "        tfh_module = tfhub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2\")\n",
    "        return tfh_module\n",
    "      #tfh_module = hub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_050_192/feature_vector/2\")\n",
    "      #tfh_module = hub.Module(\"https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/1\")\n",
    "      #tfh_module = tfhub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2\")\n",
    "    else:\n",
    "        tfh_module = tfhub.Module(os.path.join(TFHUB_CACHE_DIR, 'adfe0cf8d843e3588bfb9602e32a718b12212904'))\n",
    "        return tfh_module\n",
    "\n",
    "IMAGE_SIZE = tfhub.get_expected_image_size(transfer_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XvqAnntTOP7"
   },
   "source": [
    "Preprocesamiento de las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4CGTM3KMTOP7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "    image = tf.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image /= 255.0\n",
    "    return image\n",
    "\n",
    "# Borrar cuando no es eager execute\n",
    "#ima, la = load_and_preprocess_image(facturas_root[98], facturas_label[98])\n",
    "#plt.imshow(ima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5iz8HuupTOP_"
   },
   "source": [
    "Funciones de data ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HWmiigApTOQA"
   },
   "outputs": [],
   "source": [
    "# Ingest data\n",
    "def inputfn_train():\n",
    "    image = tf.data.Dataset.from_tensor_slices(features_train)\n",
    "    image = image.map(load_and_preprocess_image)\n",
    "    \n",
    "    label = tf.data.Dataset.from_tensor_slices(tf.cast(labels_train, tf.int64))\n",
    "    \n",
    "    ds_image_label = tf.data.Dataset.zip((image, label))    \n",
    "    ds_image_label = ds_image_label.shuffle(buffer_size=len(features_train))\n",
    "    ds_image_label = ds_image_label.repeat(None) # Repeticion infinita, son los epochs\n",
    "    ds_image_label = ds_image_label.batch(32)\n",
    "    ds_image_label = ds_image_label.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return ds_image_label\n",
    "\n",
    "def inputfn_eval():\n",
    "    image = tf.data.Dataset.from_tensor_slices(features_val)\n",
    "    image = image.map(load_and_preprocess_image)\n",
    "    \n",
    "    label = tf.data.Dataset.from_tensor_slices(tf.cast(labels_val, tf.int64))\n",
    "    \n",
    "    ds_image_label = tf.data.Dataset.zip((image, label))    \n",
    "    ds_image_label = ds_image_label.repeat(1) # Repeticion infinita, son los epochs\n",
    "    ds_image_label = ds_image_label.batch(32)\n",
    "    ds_image_label = ds_image_label.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return ds_image_label\n",
    "\n",
    "def inputfn_pred():\n",
    "    pass\n",
    "\n",
    "def inputfn_serving():\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qxkgrtfjTOQD"
   },
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H7I7D5qTTOQE"
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    # Transfer learning\n",
    "    tfh_module = transfer_model()\n",
    "\n",
    "    transformed_features = tfh_module(features)\n",
    "    logits = tf.layers.dense(transformed_features, len(features_main)) \n",
    "    probabilities = tf.nn.softmax(logits)\n",
    "        \n",
    "    if (mode != tf.estimator.ModeKeys.PREDICT):\n",
    "        one_hot_labels = tf.one_hot(labels, len(features_main)) #tf.one_hot(len(proveedores))\n",
    "        loss = tf.losses.softmax_cross_entropy(one_hot_labels, logits)\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "        train_op = tf.contrib.training.create_train_op(loss, optimizer)\n",
    "        accuracy = tf.metrics.accuracy(labels, tf.argmax(probabilities, axis=-1))\n",
    "        metrics = {'acc': accuracy}\n",
    "    else:\n",
    "        loss = optimizer = train_op = metrics = None\n",
    "    \n",
    "    model = tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                       loss=loss,\n",
    "                                       train_op=train_op,\n",
    "                                       predictions={'proba': probabilities, 'class': tf.argmax(probabilities, axis=-1)},\n",
    "                                       eval_metric_ops=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mq3O2k01TOQH"
   },
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 140805,
     "status": "ok",
     "timestamp": 1562353528601,
     "user": {
      "displayName": "Hern√°n Lopez Archila",
      "photoUrl": "https://lh4.googleusercontent.com/-notp8jonoeY/AAAAAAAAAAI/AAAAAAAAfV4/x2JEFyvg6TM/s64/photo.jpg",
      "userId": "11762393844550192215"
     },
     "user_tz": 300
    },
    "id": "8lqeSaK4TOQI",
    "outputId": "353dd82c-b818-45be-8c93-864d835afa47"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0707 23:09:40.082838 4522362304 deprecation.py:323] From /Users/hdla/Documents/Proyectos/ML/venv/MILE/lib/python3.7/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'acc': 0.9628099, 'loss': 0.17549129, 'global_step': 150}, [])\n",
      "393.11907601356506\n"
     ]
    }
   ],
   "source": [
    "run_config = tf.estimator.RunConfig(model_dir='./models/trained',\n",
    "                                   save_summary_steps=10,\n",
    "                                   save_checkpoints_steps=10,\n",
    "                                   log_step_count_steps=10)\n",
    "\n",
    "model = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                              config=run_config)\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=inputfn_train,\n",
    "                                   max_steps=150)\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=inputfn_eval)\n",
    "\n",
    "start = time.time()\n",
    "out = tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n",
    "print(out)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-0f863f0995a7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-0f863f0995a7>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorboard --logdir {'./models/trained'}\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tensorboard --logdir './models/trained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "procesamiento_estimator1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
