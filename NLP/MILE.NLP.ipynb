{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MILE.NLP.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BEVitTXo5YQr","colab_type":"text"},"source":["# Caracteristicas\n","* Data normalizada = No\n","* Funcion de entrada de datos = tf.estimator.inputs.pandas_input_fn\n","* Modelo = DNNClassifier canned\n","\n","tomado de\n","*  https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub\n","*  https://colab.research.google.com/github/tensorflow/hub/blob/master/docs/tutorials/text_classification_with_tf_hub.ipynb\n","*  https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/cross_lingual_similarity_with_tf_hub_multilingual_universal_encoder.ipynb#scrollTo=8xdAogbxJDTD"]},{"cell_type":"markdown","metadata":{"id":"Jozsw4zwsAL3","colab_type":"text"},"source":["# Librerias"]},{"cell_type":"code","metadata":{"id":"ovCH4Mwhv6Er","colab_type":"code","colab":{}},"source":["# Instalar TFHub\n","!pip install -q tensorflow-hub"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m-OqLTeOwVzM","colab_type":"code","outputId":"28e72842-651a-4c65-e05e-d8acf571326c","executionInfo":{"status":"ok","timestamp":1561143847197,"user_tz":300,"elapsed":4950,"user":{"displayName":"Hern치n Lopez Archila","photoUrl":"https://lh4.googleusercontent.com/-notp8jonoeY/AAAAAAAAAAI/AAAAAAAAfV4/x2JEFyvg6TM/s64/photo.jpg","userId":"11762393844550192215"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Librerias principales\n","import tensorflow as tf\n","import tensorflow_hub as tfh\n","import numpy as np\n","print(tf.__version__)\n","\n","# Librerias accesorias\n","import re\n","import os\n","import pandas as pd\n","\n","# Disminucion de los mensajes solo aquellos que dan error\n","tf.logging.set_verbosity(tf.logging.ERROR)\n","\n","# Parametros de configuracion"],"execution_count":2,"outputs":[{"output_type":"stream","text":["1.14.0-rc1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eDDCTkZDsEvn","colab_type":"text"},"source":["# Data"]},{"cell_type":"markdown","metadata":{"id":"RNCw0m2s9axg","colab_type":"text"},"source":["## Preprocessing"]},{"cell_type":"code","metadata":{"id":"pPMfapaEs8qP","colab_type":"code","outputId":"10629617-7696-467e-d168-8b05125455cb","executionInfo":{"status":"ok","timestamp":1561143879080,"user_tz":300,"elapsed":36823,"user":{"displayName":"Hern치n Lopez Archila","photoUrl":"https://lh4.googleusercontent.com/-notp8jonoeY/AAAAAAAAAAI/AAAAAAAAfV4/x2JEFyvg6TM/s64/photo.jpg","userId":"11762393844550192215"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["# 1.1.1 Load all files from a directory in a DataFrame\n","def load_directory_data(directory):\n","  data = {}\n","  data[\"sentence\"] = []\n","  data[\"sentiment\"] = []\n","  for file_path in os.listdir(directory):\n","    with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n","      data[\"sentence\"].append(f.read())\n","      data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n","  \n","  return pd.DataFrame.from_dict(data)\n","\n","# 1.1 Merge positive and negative examples, add a polarity column and shuffle\n","def load_dataset(directory):\n","  pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n","  neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n","  pos_df[\"polarity\"] = 1\n","  neg_df[\"polarity\"] = 0\n","  \n","  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n","  \n","# 1 Download and process the dataset files\n","def download_and_load_datasets(force_download=False):\n","  dataset = tf.keras.utils.get_file(fname=\"aclImdb.tar.gz\",\n","                                   origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n","                                   extract=True,\n","                                   cache_dir=\"/content\")\n","  \n","  train_df = load_dataset(os.path.join(os.path.dirname(dataset),\"aclImdb\", \"train\"))\n","  test_df  = load_dataset(os.path.join(os.path.dirname(dataset),\"aclImdb\", \"test\"))\n","  \n","  return train_df, test_df\n","\n","train_df, test_df = download_and_load_datasets()\n","train_df.head()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","84131840/84125825 [==============================] - 2s 0us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>sentiment</th>\n","      <th>polarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>We have to remember that the 50's were practic...</td>\n","      <td>8</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Something about \"Paulie\" touched my heart as f...</td>\n","      <td>10</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I can't say too much about Kalifornia as sadly...</td>\n","      <td>7</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I saw this movie when I was about 8-years-old ...</td>\n","      <td>8</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Go, Igor, go, you are the proof that Slovenian...</td>\n","      <td>10</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence sentiment  polarity\n","0  We have to remember that the 50's were practic...         8         1\n","1  Something about \"Paulie\" touched my heart as f...        10         1\n","2  I can't say too much about Kalifornia as sadly...         7         1\n","3  I saw this movie when I was about 8-years-old ...         8         1\n","4  Go, Igor, go, you are the proof that Slovenian...        10         1"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"gMRHfgcL9fNo","colab_type":"text"},"source":["## Ingestion functions"]},{"cell_type":"code","metadata":{"id":"atpFw7_VBA5P","colab_type":"code","colab":{}},"source":["# Data ingest\n","def train_input_fn():  \n","  dataset = tf.data.Dataset.from_tensor_slices(({'sentence': np.array(train_df['sentence'])},\n","                                                train_df['polarity']))\n","\n","  return dataset.shuffle(100).repeat(None).batch(100).prefetch(tf.data.experimental.AUTOTUNE)\n","\n","def eval_input_fn():\n","   return tf.estimator.inputs.pandas_input_fn(x=train_df,\n","                                             y=train_df[\"polarity\"],\n","                                             num_epochs=None,\n","                                             shuffle=False)\n","\n","def test_input_fn():\n","  return tf.estimator.inputs.pandas_input_fn(x=test_df,\n","                                            y=test_df[\"polarity\"],\n","                                            num_epochs=None,\n","                                            shuffle=False)\n","\n","def serving_input_fn():\n","  def _input_fn():\n","    json_feature_placeholders = {'sentence': tf.placeholder(tf.string, [None])}\n","    features = json_feature_placeholders\n","    return tf.estimator.export.ServingInputReceiver(features, json_feature_placeholders)\n","  return _input_fn"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gUp7woF0-S83","colab_type":"text"},"source":["# Modelo"]},{"cell_type":"markdown","metadata":{"id":"kRswYLXi99Xx","colab_type":"text"},"source":["## Features, variables y placeholders"]},{"cell_type":"code","metadata":{"id":"0RnaDIbz-drP","colab_type":"code","colab":{}},"source":["feature_column = tfh.text_embedding_column(key=\"sentence\",\n","                                          module_spec=\"https://tfhub.dev/google/nnlm-en-dim128/1\",\n","                                          trainable=True)\n","\n","#module = tfh.Module(\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n","#print(module.get_input_info_dict(), module.get_output_info_dict())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PEi3sLp0iH5O","colab_type":"text"},"source":["## Estimador"]},{"cell_type":"code","metadata":{"id":"qqlWr-u-0cqY","colab_type":"code","colab":{}},"source":["# Modelo: DNN canned\n","estimator = tf.estimator.DNNClassifier(hidden_units=[500, 100],\n","                                       feature_columns=[feature_column],\n","                                       n_classes=2,\n","#                                       activation_fn=tf.nn.relu,\n","#                                       dropout=0.1,\n","                                       optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))\n","\n","# Serving: model\n","export_latest = tf.estimator.LatestExporter('exporter',\n","                                           serving_input_receiver_fn=serving_input_fn())\n","\n","# Produccion: data\n","train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn,\n","                                   max_steps=1000)\n","\n","eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn(),\n","                                 exporters=export_latest)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LdsgP9_7iUXm","colab_type":"text"},"source":["## Entrenamiento y evaluacion, validacion, test y prediccion"]},{"cell_type":"code","metadata":{"id":"el16X3gfiS44","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"cb275e4c-25ae-4969-b9bb-0ea1034f60c0","executionInfo":{"status":"ok","timestamp":1561143942687,"user_tz":300,"elapsed":100401,"user":{"displayName":"Hern치n Lopez Archila","photoUrl":"https://lh4.googleusercontent.com/-notp8jonoeY/AAAAAAAAAAI/AAAAAAAAfV4/x2JEFyvg6TM/s64/photo.jpg","userId":"11762393844550192215"}}},"source":["# Entrenamiento y evaluacion\n","tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'accuracy': 0.9338281,\n","  'accuracy_baseline': 0.5001562,\n","  'auc': 0.9803551,\n","  'auc_precision_recall': 0.9808867,\n","  'average_loss': 0.18347463,\n","  'global_step': 1000,\n","  'label/mean': 0.5001562,\n","  'loss': 23.484753,\n","  'precision': 0.9457551,\n","  'prediction/mean': 0.48596093,\n","  'recall': 0.9204936},\n"," [b'/tmp/tmp72rosmqu/export/exporter/1561143941'])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"yAYLBVVotaDu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"2b27298c-2487-4108-e14b-6d28009eb6c7","executionInfo":{"status":"ok","timestamp":1561143944683,"user_tz":300,"elapsed":102387,"user":{"displayName":"Hern치n Lopez Archila","photoUrl":"https://lh4.googleusercontent.com/-notp8jonoeY/AAAAAAAAAAI/AAAAAAAAfV4/x2JEFyvg6TM/s64/photo.jpg","userId":"11762393844550192215"}}},"source":["# Prediccion\n","predict = {}\n","predict[\"sentence\"] = []\n","predict[\"sentence\"].append(test_df['sentence'][3])\n","predict_pd = pd.DataFrame.from_dict(predict)\n","print(predict_pd)\n","print('***********')\n","\n","#predictions = estimator.predict(input_fn=test_input_fn())\n","predictions = estimator.predict(input_fn=tf.estimator.inputs.pandas_input_fn(x=predict_pd, num_epochs=None, shuffle=False))\n","\n","#for items in predictions:\n","#  print(items)\n","\n","import itertools\n","print([pred['logistic'] for pred in list(itertools.islice(predictions, len(predict_pd)))])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["                                            sentence\n","0  As you can tell from the other comments, this ...\n","***********\n","[array([0.00061354], dtype=float32)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UerdB6AHYOOV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}